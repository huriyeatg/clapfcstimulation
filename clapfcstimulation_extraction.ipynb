{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: clapfcstimulation\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, pickle, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import main_funcs as mfun\n",
    "import utils_funcs as utils\n",
    "import plot_funcs as pfun\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import glob\n",
    "from scipy.signal import resample\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "warnings.filterwarnings(\"ignore\", category= FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category= DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "\n",
    "pfun.set_figure()\n",
    "\n",
    "infoPath = 'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\infoForAnalysis.pkl'\n",
    "info = pd.read_pickle(infoPath) \n",
    "\n",
    "## Parameters\n",
    "fRate = 1000/30\n",
    "pre_frames, post_frames, analysisWindowDur, simulationDur = pfun.set_analysisParams ()\n",
    "responsiveness_test_duration = 1000.0 #in ms\n",
    "simulationDur_ms = 350.0 # in ms \n",
    "simulationDur  = int(np.ceil(simulationDur_ms/fRate))\n",
    "shutterLength  = int(np.round(simulationDur_ms/fRate))\n",
    "tTypes = ['All','Both', 'onlyOpto', 'onlyVis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all recordings - MUST BE RUN TO UPDATE THE INFO FILE\n",
    "# For each recording one file saved, each index is a cell \n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "   savepathname = info.recordingList.analysispathname[ind]\n",
    "   filenamePAQ_analysis = [f for f in glob.glob(savepathname + 'extracted_variables.pkl')] # paq analysis file\n",
    "   if  (info.recordingList.calciumImaging[ind] ==0) & (info.recordingList.pupilImaging[ind] ==0):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   elif (len(filenamePAQ_analysis)==1):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 1 \n",
    "   elif (info.recordingList.stimuliFamiliarity[ind] == 5):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   elif (info.recordingList.stimuliFamiliarity[ind] == 10):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   else:\n",
    "      try:\n",
    "      #if ind ==125:\n",
    "         print(str(ind) + ': Creating: ' + info.recordingList.analysispathname[ind])\n",
    "         #Create a huge dictionary with all cells and parameters for each cell\n",
    "         pathname = info.recordingList.analysispathname[ind]\n",
    "         print('Creating the dict for:' + pathname)\n",
    "\n",
    "         ########## Organise stimuli times \n",
    "         if  (info.recordingList.paqExtraction[ind] ==1) :\n",
    "            paqData = pd.read_pickle (pathname +'paq-data.pkl')\n",
    "            paqRate = paqData['rate']\n",
    "            # Get the stim start times \n",
    "            frame_clock    = utils.paq_data (paqData, 'prairieFrame', threshold_ttl=True, plot=False)\n",
    "            optoStimTimes  = utils.paq_data (paqData, 'optoLoopback', threshold_ttl=True, plot=False)\n",
    "            if   (len(optoStimTimes)>500):\n",
    "\n",
    "               print('Opto stim times is a lot , check it out : ' + str(ind))\n",
    "            else: # the frame_clock is slightly longer in paq as there are some up to a sec delay from\n",
    "               # microscope to PAQI/O software.  \n",
    "               optoStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='optoLoopback',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               visStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='maskerLED',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               shutterTimes = utils.shutter_start_frame (paq=paqData, stim_chan_name='shutterLoopback',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               # Lets organise it more for analysis friendly format\n",
    "               trialStartTimes = np.unique(np.concatenate((optoStimTimes,visStimTimes),0))\n",
    "               # final check if there is a problematic stim start\n",
    "               first_ind = np.where(np.diff(trialStartTimes)>30) # should be at least one sec between stim starts\n",
    "               first_ind = np.concatenate(([0], first_ind[0]+1))\n",
    "               trialStartTimes = np.array(trialStartTimes)\n",
    "               trialStartTimes = trialStartTimes[first_ind]\n",
    "               trialTypes = []\n",
    "               reree\n",
    "               for t in trialStartTimes:\n",
    "                  optoexist =  np.any(optoStimTimes== t)\n",
    "                  visexist  =  np.any( visStimTimes == t)\n",
    "                  if  optoexist  & visexist: \n",
    "                     trialTypes += ['Both']\n",
    "                  elif optoexist &~ visexist:\n",
    "                     trialTypes += ['onlyOpto']\n",
    "                  elif ~optoexist & visexist:\n",
    "                     trialTypes += ['onlyVis']\n",
    "                  else:\n",
    "                     trialTypes += ['CHECK']\n",
    "               trialStartTimes = shutterTimes\n",
    "               #t = [idx for idx, t_type in enumerate(trialTypes) if t_type=='Both']\n",
    "            \n",
    "            ########## Organise calcium imaging traces \n",
    "            pvals ={} \n",
    "            pvalsWilcoxon = {}\n",
    "            dffTrace ={} \n",
    "            dffTrace_mean ={}\n",
    "            dffTrace_median ={}\n",
    "            dffAfterStim1500ms_mean ={}\n",
    "            dffTrace_normalised = {}\n",
    "            dffTrace_mean_normalised ={}\n",
    "            \n",
    "            if (info.recordingList.dffExtraction[ind] ==1):\n",
    "               imData = pd.read_pickle (pathname +'imaging-data.pkl')\n",
    "               fluR      = imData['flu']\n",
    "               n_frames  = imData['n_frames']\n",
    "               flu_raw   = imData['flu_raw']\n",
    "\n",
    "               # Lets put nans for stimulated frames\n",
    "               frameTimes = np.full((1,fluR.shape[1] ), False) # create a full false array\n",
    "               for sT in shutterTimes:\n",
    "                  frameTimes[:,sT:(sT+shutterLength)] = True\n",
    "               fluR[:, frameTimes[0,:]] = np.nan\n",
    "\n",
    "               # clean detrended traces\n",
    "               flu = utils.clean_traces(fluR)\n",
    "               flu_normalised = mfun.norm_to_zero_one (flu)\n",
    "\n",
    "               ### Look for responsiveness for 4 trial types\n",
    "               for t in tTypes:\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  else:\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "                                                               post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "                                                               testType ='ttest')\n",
    "                     pvals[t] = pval\n",
    "                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "                                                               post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "                                                               testType ='wilcoxon')\n",
    "                     pvalsWilcoxon[t] = pval\n",
    "               nCell = len(flu)\n",
    "               print('number of cell: ' + str(nCell))\n",
    "               ### Get dff values for 4 trial types\n",
    "               for indx, t in enumerate(tTypes) :\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  else:\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     dffTrace[t]      = utils.flu_splitter(flu, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     dffTrace_mean[t] = np.mean(dffTrace[t],2) # Cell x time\n",
    "                     dffTrace_median[t] = np.median(dffTrace[t],2) # Cell x time\n",
    "                     dffAfterStim1500ms_mean[t] = np.nanmean(dffTrace_mean[t][:, (pre_frames+simulationDur): (pre_frames + analysisWindowDur)],1)\n",
    "                     \n",
    "                     dffTrace_normalised[t] = utils.flu_splitter(flu_normalised, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     dffTrace_mean_normalised[t] = np.mean (dffTrace_normalised[t],2) # Cell x time ( mean - 2)\n",
    "                           #create dff for all cells\n",
    "               # PLOT EACH CELL RESPONSE\n",
    "               for indC, cell_dff in enumerate(flu):\n",
    "                  plotTrue = True\n",
    "                  if (len(optoStimTimes)==40): \n",
    "                     tTypes = ['Both', 'onlyOpto', 'onlyVis']\n",
    "                     plotTrue =  (pvals['onlyVis'][indC] < 1e-6) or (pvals['onlyOpto'][indC] < 1e-6) or (pvals['Both'][indC] < 1e-6)\n",
    "                  elif (len(optoStimTimes)==20):\n",
    "                     tTypes = ['Both', 'onlyVis']\n",
    "                     plotTrue =  (pvals['onlyVis'][indC] < 1e-6)  or (pvals['Both'][indC] < 1e-6)\n",
    "\n",
    "                  if plotTrue:\n",
    "                     fig = plt.figure(str(indC))\n",
    "                     plt.switch_backend('Agg')\n",
    "                     for indx, t in enumerate(tTypes):\n",
    "                           pfun.lineplot_withSEM (data=dffTrace[t][indC], colorInd = indx, label=t)\n",
    "                           pfun.save_figure(pathname[-20:-1]+'_DFF_mean_' + str(indC),info.figsPath +'\\\\cellDFF_Chrimson')\n",
    "                           plt.close(fig)\n",
    "            else:\n",
    "               imData =[]\n",
    "            ########## Organise pupil  traces \n",
    "            pupilTrace ={}\n",
    "            pupilTrace_mean ={}\n",
    "            pupilTraceVer ={}\n",
    "            pupilTrace_meanVer ={}\n",
    "\n",
    "            if (info.recordingList.pupilExtraction[ind] ==1): \n",
    "               pupilData = pd.read_pickle (pathname +'pupil-data.pkl')\n",
    "               pupilrawh = pupilData['horizontalDis']\n",
    "               pupilrawv = pupilData['verticalDis']\n",
    "               pupilQualityh = pupilData['horizontallikelihood']\n",
    "               pupilQualityv = pupilData['verticallikelihood']\n",
    "\n",
    "               for indx, t in enumerate(tTypes) :\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  else:\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     pupilTrace[t]  = utils.trace_splitter(pupilrawh, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     pupilTrace_mean[t]  = np.mean(pupilTrace[t],2) # Cell x time\n",
    "\n",
    "                     pupilTraceVer[t]  = utils.trace_splitter(pupilrawv, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     pupilTrace_meanVer[t]  = np.mean(pupilTraceVer[t],2) # Cell x tim\n",
    "\n",
    "            #lets get recording info\n",
    "            animalID = []\n",
    "            x_coordinate = []\n",
    "            y_coordinate = []\n",
    "            z_coordinate = []\n",
    "            stimuliFamilarity = []\n",
    "            dataQuality =[]\n",
    "            recData = []\n",
    "            recID   = []\n",
    "            cellID  = []\n",
    "\n",
    "            if len(imData)>0:\n",
    "               imStats = imData['stat']\n",
    "               for idx, cell_flu in enumerate(flu): # from suite2p website: med: (y,x) center of cell\n",
    "                  x_coordinate += [np.round(imStats[idx]['med'][1] *512/558.9) + info.recordingList['x-coordinate'] [ind]]\n",
    "                  y_coordinate += [np.round(imStats[idx]['med'][0] *512/558.9) + info.recordingList['y-coordinate'] [ind]]\n",
    "                  z_coordinate += [info.recordingList['z-coordinate'] [ind]]\n",
    "                  animalID     += [info.recordingList['animalID'] [ind]]\n",
    "                  stimuliFamilarity += [info.recordingList['stimuliFamiliarity'] [ind]]\n",
    "                  dataQuality  += [info.recordingList['dataQuality'] [ind]]\n",
    "                  recData  += [info.recordingList['recordingDate'] [ind]]\n",
    "                  recID    += [info.recordingList['recordingID'] [ind]]\n",
    "                  cellID   += [idx]\n",
    "            else:\n",
    "               x_coordinate = [np.nan]\n",
    "               y_coordinate = [np.nan]\n",
    "               z_coordinate = [np.nan]\n",
    "               animalID     = [info.recordingList['animalID'] [ind]]\n",
    "               stimuliFamilarity = [info.recordingList['stimuliFamiliarity'] [ind]]\n",
    "               dataQuality  = [info.recordingList['dataQuality'] [ind]]\n",
    "               recData  = [info.recordingList['recordingDate'] [ind]]\n",
    "               recID    = [info.recordingList['recordingID'] [ind]]\n",
    "               cellID   = [np.nan]\n",
    "\n",
    "            #save outputs for population analysis\n",
    "            savename = info.recordingList.analysispathname[ind] + 'extracted_variables.pkl'\n",
    "            with open(savename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "               pickle.dump([trialStartTimes, trialTypes, pvals, dffTrace, \n",
    "                           dffTrace_mean, dffAfterStim1500ms_mean,\n",
    "                           x_coordinate,y_coordinate,z_coordinate,\n",
    "                           animalID,stimuliFamilarity,pvalsWilcoxon, dataQuality,\n",
    "                           recData, recID, cellID, pupilTrace, pupilTrace_mean, \n",
    "                           pupilQualityh, pupilTraceVer, pupilTrace_meanVer, pupilQualityv,\n",
    "                           dffTrace_normalised,dffTrace_mean_normalised, dffTrace_median], f)\n",
    "            info.recordingList.loc[ind,'extractedVar'] = 1\n",
    "         else:\n",
    "            print('FAILED: no paq file : ' + pathname)\n",
    "            info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "      except:\n",
    "         print('FAILED: ' + pathname)\n",
    "         info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   \n",
    "\n",
    "#save info \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-extracted.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump(info, f)\n",
    "print('All should be done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version: 31/03/34 - Optimised merge code\n",
    "## Merge all datapoints & save them in a dictionary\n",
    "\n",
    "infoPath = 'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\infoForAnalysis-extracted.pkl'\n",
    "info = pd.read_pickle(infoPath)\n",
    "\n",
    "# Initialize empty or None types for variables to be aggregated.\n",
    "dff_traceBoth, dff_traceVis, dff_traceOpto = None, None, None\n",
    "dff_traceBoth_median, dff_traceVis_median, dff_traceOpto_median = None, None, None\n",
    "dff_traceBoth_normalised, dff_traceVis_normalised, dff_traceOpto_normalised = None, None, None\n",
    "pupil_traceBoth, pupil_traceVis, pupil_traceOpto = None, None, None\n",
    "pupilID, x_coordinate, y_coordinate, z_coordinate = [], [], [], []\n",
    "animalID, stimuliFamilarity, dataQuality, recData, recID, cellID = [], [], [], [], [], []\n",
    "pvalsBoth, pvalsVis, pvalsOpto = [], [], []\n",
    "dff_meanBothValue, dff_meanVisValue, dff_meanOptoValue = [], [], []\n",
    "\n",
    "# Create the main variables for plots by merging the extracted variables from all recordings\n",
    "ty = 0\n",
    "indPupil = 0\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "   if (info.recordingList.extractedVar[ind] ==1):\n",
    "        # load the extracted values\n",
    "        pathname = info.recordingList.analysispathname[ind] \n",
    "        extData = pd.read_pickle (pathname + 'extracted_variables.pkl')\n",
    "        sys.stdout.write(f'\\rExtraction started for : {ind}')\n",
    "        sys.stdout.flush() \n",
    "\n",
    "        len_cellID   = len(extData[15])\n",
    "        if len_cellID==0:\n",
    "            len_cellID=1\n",
    "\n",
    "        # Get Dff traces MEAN\n",
    "        dff_trace = extData[4] #4 for mean, 24 for median\n",
    "        shape = (len_cellID, 240) \n",
    "        dff_traceBoth =mfun.update_dff_traces(dff_traceBoth, dff_trace, 'Both', shape)\n",
    "        dff_traceVis = mfun.update_dff_traces(dff_traceVis, dff_trace, 'onlyVis', shape)\n",
    "        dff_traceOpto = mfun.update_dff_traces(dff_traceOpto, dff_trace, 'onlyOpto', shape)\n",
    "\n",
    "        # Get Dff traces MEDIAN\n",
    "        dff_trace = extData[24] #4 for mean, 24 for median\n",
    "        shape = (len_cellID, 240) \n",
    "        dff_traceBoth_median =mfun.update_dff_traces(dff_traceBoth_median, dff_trace, 'Both', shape)\n",
    "        dff_traceVis_median = mfun.update_dff_traces(dff_traceVis_median, dff_trace, 'onlyVis', shape)\n",
    "        dff_traceOpto_median = mfun.update_dff_traces(dff_traceOpto_median, dff_trace, 'onlyOpto', shape)\n",
    "\n",
    "        # Get Dff traces NORMALISED\n",
    "        dff_trace = extData[23] #4 for mean, 24 for median\n",
    "        shape = (len_cellID, 240)\n",
    "        dff_traceBoth_normalised =mfun.update_dff_traces(dff_traceBoth_normalised, dff_trace, 'Both', shape)\n",
    "        dff_traceVis_normalised = mfun.update_dff_traces(dff_traceVis_normalised, dff_trace, 'onlyVis', shape)\n",
    "        dff_traceOpto_normalised = mfun.update_dff_traces(dff_traceOpto_normalised, dff_trace, 'onlyOpto', shape)\n",
    "\n",
    "        # Get Pupil traces\n",
    "        indPupil, pupilID, pupil_traceBoth, pupil_traceVis, pupil_traceOpto = mfun.update_pupil_traces(\n",
    "            extData, len_cellID, indPupil, pupilID, pupil_traceBoth, pupil_traceVis, pupil_traceOpto)\n",
    "        \n",
    "        # Get P values\n",
    "\n",
    "        pvals = extData[2]\n",
    "        if len(pvals)>0:\n",
    "            pvalsBoth += pvals['Both'].tolist()\n",
    "            pvalsVis  += pvals['onlyVis'].tolist()\n",
    "\n",
    "            if 'onlyOpto' in dff_trace:\n",
    "                pvalsOpto  += pvals['onlyOpto'].tolist()\n",
    "            else:\n",
    "                fakeOpto = np.empty (np.shape(pvals['Both']))\n",
    "                fakeOpto[:] = 5\n",
    "                pvalsOpto  += fakeOpto.tolist()\n",
    "        else:\n",
    "            pvalsBoth += [5]\n",
    "            pvalsVis  += [5]\n",
    "            pvalsOpto += [5]\n",
    "\n",
    "         \n",
    "        # Get  cell-related information\n",
    "        x_coordinate += extData[6]\n",
    "        y_coordinate += extData[7]\n",
    "        z_coordinate += extData[8]\n",
    "        animalID     += extData[9]\n",
    "        stimuliFamilarity += extData[10]\n",
    "        dataQuality += extData[12]\n",
    "        recData  += extData[13]\n",
    "        recID    += extData[14]\n",
    "        cellID   += extData[15]\n",
    "\n",
    "########################################\n",
    "####################### Organise & save files\n",
    "\n",
    "fRate = 1000/30.0\n",
    "pre_frames    = 2000.0# in ms\n",
    "pre_frames    = int(np.ceil(pre_frames/fRate))\n",
    "post_frames   = 6000.0 # in ms\n",
    "post_frames   = int(np.ceil(post_frames/fRate))\n",
    "analysis_time = 1500.0 # in ms\n",
    "analysis_time = int(np.ceil(analysis_time/fRate))\n",
    "simulationDur_ms = 350.0 # in ms\n",
    "simulationDur = int(np.ceil(simulationDur_ms/fRate))\n",
    "pupil_resample_num = int(6*5)\n",
    "\n",
    "### Lets normalise to baseline - MEAN\n",
    "traces = {  'Vis': dff_traceVis,\n",
    "            'Opto': dff_traceOpto,\n",
    "            'Both': dff_traceBoth}\n",
    "\n",
    "dff_traceVis_normalisedtopre, dff_traceOpto_normalisedtopre, dff_traceBoth_normalisedtopre = (\n",
    "    mfun.normalize_to_baseline(traces[key], pre_frames) for key in traces)\n",
    "### Lets do tiny cleaning for imaging traces -MEDIAN\n",
    "traces = {  'Vis': dff_traceVis_median,\n",
    "            'Opto': dff_traceOpto_median,\n",
    "            'Both': dff_traceBoth_median}\n",
    "dff_traceVis_normalisedtopre_median, dff_traceOpto_normalisedtopre_median, dff_traceBoth_normalisedtopre_median = (\n",
    "    mfun.normalize_to_baseline(traces[key], pre_frames) for key in traces)\n",
    "\n",
    "### Lets do tiny cleaning for pupil traces\n",
    "traces = {  'Vis': pupil_traceVis,\n",
    "            'Opto': pupil_traceOpto,\n",
    "            'Both': pupil_traceBoth}\n",
    "pupil_traceVis, pupil_traceOpto, pupil_traceBoth = (\n",
    "    mfun.normalize_to_baseline(traces[key], pre_frames) for key in traces)\n",
    "\n",
    "pupil_traceOpto = resample(pupil_traceOpto, pupil_resample_num, axis=1)\n",
    "pupil_traceVis = resample(pupil_traceVis, pupil_resample_num, axis=1)\n",
    "pupil_traceBoth = resample(pupil_traceBoth, pupil_resample_num, axis=1)\n",
    "\n",
    "#  More version of dff traces\n",
    "dff_meanBoth = np.nanmean(dff_traceBoth [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1)\n",
    "dff_meanVis  = np.nanmean(dff_traceVis  [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1)\n",
    "dff_meanOpto = np.nanmean(dff_traceOpto [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1) \n",
    "\n",
    "zdff_traceBoth = stats.zscore (dff_traceBoth, nan_policy='omit')\n",
    "zdff_traceVis  = stats.zscore (dff_traceVis, nan_policy='omit')\n",
    "zdff_traceOpto = stats.zscore (dff_traceOpto, nan_policy='omit')\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForSelectingInterestedCells.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((animalID, stimuliFamilarity, dataQuality,\n",
    "                 recData, recID, cellID, \n",
    "                 pvalsBoth, pvalsVis, pvalsOpto,\n",
    "                 dff_meanVis, dff_meanBoth, \n",
    "                 dff_meanOpto, pupilID),f)\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth, dff_traceVis, dff_traceOpto), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_median.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_median, dff_traceVis_median, dff_traceOpto_median), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_normalised.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalised, dff_traceVis_normalised, dff_traceOpto_normalised), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_normalisedtoPre.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalisedtopre, dff_traceVis_normalisedtopre, dff_traceOpto_normalisedtopre), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_normalisedtoPre_median.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalisedtopre_median, dff_traceVis_normalisedtopre_median, dff_traceOpto_normalisedtopre_median), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_position.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((x_coordinate, y_coordinate, z_coordinate ), f)\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlottingPupil.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((pupil_traceVis, pupil_traceBoth, pupil_traceOpto ), f)\n",
    "print('\\nAll should be done!!')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More stats\n",
    "\n",
    "infoPath = 'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\infoForAnalysis-extracted.pkl'\n",
    "info = pd.read_pickle(infoPath)\n",
    "\n",
    "# Create the main variables for plots by merging the extracted variables from all recordings\n",
    "pre_frames, post_frames, analysis_frame, simulationDur = pfun.set_analysisParams ()\n",
    "pre_analysisWindow = np.arange(pre_frames - analysis_frame, pre_frames)\n",
    "post_analysisWindow = np.arange((pre_frames+simulationDur), (pre_frames + simulationDur + analysis_frame))\n",
    "\n",
    "# Create dictionaries to store the values\n",
    "variance_dict_pre = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "variance_dict_post = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "mi_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "snr_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "abs_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "crosscorr_dict_pre = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "crosscorr_dict_post = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    if info.recordingList.extractedVar[ind] == 1:\n",
    "        # Load the extracted values\n",
    "        pathname = info.recordingList.analysispathname[ind]\n",
    "        extData = pd.read_pickle(pathname + 'extracted_variables.pkl')\n",
    "        sys.stdout.write(f'\\rMore stats are calculating for : {ind}')\n",
    "        sys.stdout.flush() \n",
    "        len_cellID = len(extData[15])\n",
    "\n",
    "        # Loop through the datasets ('Both', 'onlyVis', 'onlyOpto')\n",
    "        for dataset in ['Both', 'onlyVis', 'onlyOpto']:\n",
    "            dff_trace = extData[3]\n",
    "            if dataset in dff_trace:\n",
    "                flu = dff_trace[dataset]\n",
    "                # Calculate variance\n",
    "                variance_value_pre = mfun.variance_cell_rates(flu, pre_analysisWindow)\n",
    "                variance_dict_pre[dataset] += variance_value_pre.tolist()\n",
    "                variance_value_post = mfun.variance_cell_rates(flu, post_analysisWindow)\n",
    "                variance_dict_post[dataset] += variance_value_post.tolist()\n",
    "\n",
    "                # Calculate cross-correlation\n",
    "                crosscorr_value_post = mfun.mean_cross_correlation(flu, pre_analysisWindow)\n",
    "                crosscorr_dict_pre[dataset] += crosscorr_value_post.tolist()\n",
    "\n",
    "                crosscorr_value_post = mfun.mean_cross_correlation(flu, post_analysisWindow)\n",
    "                crosscorr_dict_post[dataset] += crosscorr_value_post.tolist()\n",
    "\n",
    "                # Calculate SNR\n",
    "                snr_value = mfun.calculate_SNR(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                snr_dict[dataset] += snr_value.tolist()\n",
    "\n",
    "                # Calculate Absolute Value\n",
    "                abs_value = mfun.calculate_absMagnitude(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                abs_dict[dataset] += abs_value.tolist()\n",
    "\n",
    "                # Calculate MI (if applicable)\n",
    "                mi_value = mfun.calculate_MI(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                mi_dict[dataset] += mi_value.tolist()\n",
    "            else:\n",
    "                if 'onlyOpto' in dff_trace:\n",
    "                    fakeOpto = np.empty(np.shape(dff_trace['Both']))\n",
    "                else:\n",
    "                    fakeOpto = np.empty(1)\n",
    "                fakeOpto[:] = np.nan\n",
    "\n",
    "                variance_dict_pre[dataset] += fakeOpto.tolist()\n",
    "                variance_dict_post[dataset] += fakeOpto.tolist()\n",
    "                crosscorr_dict_pre[dataset] += fakeOpto.tolist()\n",
    "                crosscorr_dict_post[dataset] += fakeOpto.tolist()\n",
    "                snr_dict[dataset] += fakeOpto.tolist()\n",
    "                abs_dict[dataset] += fakeOpto.tolist()\n",
    "                mi_dict[dataset] += fakeOpto.tolist()\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_moreStats.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((variance_dict_pre, variance_dict_post, snr_dict, mi_dict,\n",
    "                 crosscorr_dict_pre,crosscorr_dict_post, abs_dict), f)\n",
    "    \n",
    "print('\\nCompleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross correlation matrix extraction\n",
    "\n",
    "interestedCohorts = [ 'Chrimson']\n",
    "trainedLevels = [ 'Trained']\n",
    "responsivenessTypes = ['All', 'None']\n",
    "stimTypes = ['Visual', 'Visual + Opto']\n",
    "sortType = 'Visual'\n",
    "fRate = 30\n",
    "simulationDur_ms = 350.0 # in ms\n",
    "simulationDur = int(np.ceil(simulationDur_ms/fRate))\n",
    "pre_frames    = 2000.0# in ms\n",
    "pre_frames    = int(np.ceil(pre_frames/fRate))\n",
    "preStimFrames = round(simulationDur+pre_frames)\n",
    "analysisWindowDur = 1500 # in ms\n",
    "analysisWindowDurFrames = int(np.ceil(analysisWindowDur/fRate))\n",
    "postStimFrame = preStimFrames + analysisWindowDurFrames\n",
    "\n",
    "for cohort in interestedCohorts:\n",
    "    for trainedLevel in trainedLevels:\n",
    "        for responsiveness in responsivenessTypes:\n",
    "            plotDatas,animalList = pfun.createTrialvsTraceMatrix(stimTypes, 'Visual', cohort, trainedLevel=trainedLevel, condition=responsiveness)\n",
    "            \n",
    "            # Initialization for combined data and IDs\n",
    "            neural_data_combined, stimID_combined,animalID_combined = [], [],[]\n",
    "            \n",
    "            for i, data in enumerate(plotDatas):\n",
    "                segment_data = data[:, preStimFrames:postStimFrame]\n",
    "                mask = ~np.isnan(segment_data).any(axis=1)\n",
    "                filtered_data = segment_data[mask]\n",
    "                filtered_animal = animalList[i][mask]\n",
    "                neural_data_combined.append(filtered_data)\n",
    "                animalID_combined.append(filtered_animal)\n",
    "                \n",
    "                stim_ids = np.full((len(filtered_data), 3), [i, stimTypes.index(stimTypes[i]), 0])\n",
    "                stim_ids[:, 2] = stim_ids[:, 0] + stim_ids[:, 1]\n",
    "                stimID_combined.append(stim_ids)\n",
    "            \n",
    "            neural_data = np.vstack(neural_data_combined)\n",
    "            stimID = np.vstack(stimID_combined)\n",
    "            animalID = np.hstack(animalID_combined)\n",
    "            animalID  = animalID.transpose()\n",
    "\n",
    "            correlation_matrices = []\n",
    "            linkage_matrices = []\n",
    "            for i in range(len(stimTypes)):\n",
    "                data_i = neural_data[stimID[:, 0] == i]\n",
    "                corr_matrix_i = np.corrcoef(data_i)\n",
    "                distance_matrix_i = 1 - corr_matrix_i\n",
    "                Z_i = linkage(distance_matrix_i, method='single')\n",
    "                correlation_matrices.append(corr_matrix_i)\n",
    "                linkage_matrices.append(Z_i)\n",
    "            \n",
    "            # Save outputs for population analysisd\n",
    "            savename = f'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\crossCorrelation_{cohort}_{trainedLevel}_{responsiveness}.pkl'\n",
    "            with open(savename, 'wb') as f:\n",
    "                pickle.dump([linkage_matrices, correlation_matrices,\n",
    "                             animalID], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clapfcstimulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff0e9250df7e90987fa5ad44ef5c9f564e89158a37eae3ca2a18a9b188d147c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
