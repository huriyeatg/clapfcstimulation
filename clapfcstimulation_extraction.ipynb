{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: clapfcstimulation\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import main_funcs as mfun\n",
    "import utils_funcs as utils\n",
    "import plot_funcs as pfun\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import glob\n",
    "from scipy.signal import resample\n",
    "\n",
    "pfun.set_figure()\n",
    "\n",
    "infoPath = 'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\infoForAnalysis.pkl'\n",
    "info = pd.read_pickle(infoPath) \n",
    "\n",
    "## Parameters\n",
    "fRate = 1000/30\n",
    "responsiveness_test_duration = 1000.0 #in ms \n",
    "simulationDur_ms = 350.0 # in ms\n",
    "simulationDur = int(np.ceil(simulationDur_ms/fRate))\n",
    "pre_frames    = 2000.0# in ms\n",
    "pre_frames    = int(np.ceil(pre_frames/fRate))\n",
    "post_frames   = 6000.0 # in ms\n",
    "post_frames   = int(np.ceil(post_frames/fRate))\n",
    "analysisWindowDur = 1500 # in ms\n",
    "analysisWindowDur = int(np.ceil(analysisWindowDur/fRate))\n",
    "shutterLength     = int(np.round(simulationDur_ms/fRate))\n",
    "tTypes = ['All','Both', 'onlyOpto', 'onlyVis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all recordings\n",
    "# For each recording one file saved, each index is a cell \n",
    "gh = 1\n",
    "ind = gh\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "#if gh == ind:\n",
    "   savepathname = info.recordingList.analysispathname[ind]\n",
    "   filenamePAQ_analysis = [f for f in glob.glob(savepathname + '2extracted_variables.pkl')] # paq analysis file\n",
    "   if  (info.recordingList.calciumImaging[ind] ==0) & (info.recordingList.pupilImaging[ind] ==0):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   elif (len(filenamePAQ_analysis)==1):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 1 \n",
    "   elif (info.recordingList.stimuliFamiliarity[ind] == 5):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   elif (info.recordingList.stimuliFamiliarity[ind] == 10):\n",
    "      info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "   else:\n",
    "      try:\n",
    "         print(str(ind) + ': Creating: ' + info.recordingList.analysispathname[ind])\n",
    "         #Create a huge dictionary with all cells and parameters for each cell\n",
    "         pathname = info.recordingList.analysispathname[ind]\n",
    "         print('Creating the dict for:' + pathname)\n",
    "\n",
    "         ########## Organise stimuli times \n",
    "         if  (info.recordingList.paqExtraction[ind] ==1) :\n",
    "            paqData = pd.read_pickle (pathname +'paq-data.pkl')\n",
    "            paqRate = paqData['rate']\n",
    "            # Get the stim start times \n",
    "            frame_clock    = utils.paq_data (paqData, 'prairieFrame', threshold_ttl=True, plot=False)\n",
    "            optoStimTimes  = utils.paq_data (paqData, 'optoLoopback', threshold_ttl=True, plot=False)\n",
    "            if   (len(optoStimTimes)>500):\n",
    "               print('Opto stim times is a lot , check it out : ' + str(ind))\n",
    "            else: # the frame_clock is slightly longer in paq as there are some up to a sec delay from\n",
    "               # microscope to PAQI/O software.  \n",
    "               optoStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='optoLoopback',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               visStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='maskerLED',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               shutterTimes = utils.shutter_start_frame (paq=paqData, stim_chan_name='shutterLoopback',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               # Lets organise it more for analysis friendly format\n",
    "               trialStartTimes = np.unique(np.concatenate((optoStimTimes,visStimTimes),0))\n",
    "               # final check if there is a problematic stim start\n",
    "               first_ind = np.where(np.diff(trialStartTimes)>30) # should be at least one sec between stim starts\n",
    "               first_ind = np.concatenate(([0], first_ind[0]+1))\n",
    "               trialStartTimes = np.array(trialStartTimes)\n",
    "               trialStartTimes = trialStartTimes[first_ind]\n",
    "\n",
    "               trialTypes = []\n",
    "               for t in trialStartTimes:\n",
    "                  optoexist =  np.any(optoStimTimes== t)\n",
    "                  visexist  =  np.any( visStimTimes == t)\n",
    "                  if  optoexist  & visexist: \n",
    "                     trialTypes += ['Both']\n",
    "                  elif optoexist &~ visexist:\n",
    "                     trialTypes += ['onlyOpto']\n",
    "                  elif ~optoexist & visexist:\n",
    "                     trialTypes += ['onlyVis']\n",
    "                  else:\n",
    "                     trialTypes += ['CHECK']\n",
    "               trialStartTimes = shutterTimes\n",
    "               #t = [idx for idx, t_type in enumerate(trialTypes) if t_type=='Both']\n",
    "            \n",
    "            ########## Organise calcium imaging traces \n",
    "            pvals ={} \n",
    "            pvalsWilcoxon = {}\n",
    "            dffTrace ={} \n",
    "            dffTrace_mean ={}\n",
    "            dffTrace_median ={}\n",
    "            dffAfterStim1500ms_mean ={}\n",
    "            dffTrace_normalised = {}\n",
    "            dffTrace_mean_normalised ={}\n",
    "            \n",
    "            if (info.recordingList.dffExtraction[ind] ==1):\n",
    "               imData = pd.read_pickle (pathname +'imaging-data.pkl')\n",
    "               fluR      = imData['flu']\n",
    "               n_frames  = imData['n_frames']\n",
    "               flu_raw   = imData['flu_raw']\n",
    "\n",
    "               # Lets put nans for stimulated frames\n",
    "               frameTimes = np.full((1,fluR.shape[1] ), False) # create a full false array\n",
    "               for sT in shutterTimes:\n",
    "                  frameTimes[:,sT:(sT+shutterLength)] = True\n",
    "               fluR[:, frameTimes[0,:]] = np.nan\n",
    "\n",
    "               # clean detrended traces\n",
    "               flu = utils.clean_traces(fluR)\n",
    "               flu_normalised = mfun.norm_to_zero_one (flu)\n",
    "\n",
    "               ### Look for responsiveness for 4 trial types\n",
    "               for t in tTypes:\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  else:\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "                                                               post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "                                                               testType ='ttest')\n",
    "                     pvals[t] = pval\n",
    "                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "                                                               post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "                                                               testType ='wilcoxon')\n",
    "                     pvalsWilcoxon[t] = pval\n",
    "               nCell = len(flu)\n",
    "               print('number of cell: ' + str(nCell))\n",
    "               ### Get dff values for 4 trial types\n",
    "               for indx, t in enumerate(tTypes) :\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  else:\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     dffTrace[t]      = utils.flu_splitter(flu, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     dffTrace_mean[t] = np.mean(dffTrace[t],2) # Cell x time\n",
    "                     dffTrace_median[t] = np.median(dffTrace[t],2) # Cell x time\n",
    "                     dffAfterStim1500ms_mean[t] = np.nanmean(dffTrace_mean[t][:, (pre_frames+simulationDur): (pre_frames + analysisWindowDur)],1)\n",
    "                     \n",
    "                     dffTrace_normalised[t] = utils.flu_splitter(flu_normalised, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     dffTrace_mean_normalised[t] = np.mean (dffTrace_normalised[t],2) # Cell x time ( mean - 2)\n",
    "                           #create dff for all cells\n",
    "               # # PLOT EACH CELL RESPONSE\n",
    "               # for indC, cell_dff in enumerate(flu):\n",
    "               #    plotTrue = False\n",
    "               #    if (len(optoStimTimes)==40): \n",
    "               #       tTypes = ['Both', 'onlyOpto', 'onlyVis']\n",
    "               #       plotTrue =  (pvals['onlyVis'][indC] < 1e-6) or (pvals['onlyOpto'][indC] < 1e-6) or (pvals['Both'][indC] < 1e-6)\n",
    "               #    elif (len(optoStimTimes)==20):\n",
    "               #       tTypes = ['Both', 'onlyVis']\n",
    "               #       plotTrue =  (pvals['onlyVis'][indC] < 1e-6)  or (pvals['Both'][indC] < 1e-6)\n",
    "\n",
    "               #    if plotTrue:\n",
    "               #       fig = plt.figure(str(indC))\n",
    "               #       plt.switch_backend('Agg')\n",
    "               #       for indx, t in enumerate(tTypes):\n",
    "               #             pfun.lineplot_withSEM (data=dffTrace[t][indC], colorInd = indx, label=t)\n",
    "               #             pfun.save_figure(pathname[-20:-1]+'_DFF_mean_' + str(indC),info.figsPath +'\\\\cellDFF_OPN3')\n",
    "               #             plt.close(fig)\n",
    "            else:\n",
    "               imData =[]\n",
    "            ########## Organise pupil  traces \n",
    "            pupilTrace ={}\n",
    "            pupilTrace_mean ={}\n",
    "            pupilTraceVer ={}\n",
    "            pupilTrace_meanVer ={}\n",
    "\n",
    "            if (info.recordingList.pupilExtraction[ind] ==1): \n",
    "               pupilData = pd.read_pickle (pathname +'pupil-data.pkl')\n",
    "               pupilrawh = pupilData['horizontalDis']\n",
    "               pupilrawv = pupilData['verticalDis']\n",
    "               pupilQualityh = pupilData['horizontallikelihood']\n",
    "               pupilQualityv = pupilData['verticallikelihood']\n",
    "\n",
    "               for indx, t in enumerate(tTypes) :\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  else:\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     pupilTrace[t]  = utils.trace_splitter(pupilrawh, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     pupilTrace_mean[t]  = np.mean(pupilTrace[t],2) # Cell x time\n",
    "\n",
    "                     pupilTraceVer[t]  = utils.trace_splitter(pupilrawv, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     pupilTrace_meanVer[t]  = np.mean(pupilTraceVer[t],2) # Cell x tim\n",
    "\n",
    "            #lets get recording info\n",
    "            animalID = []\n",
    "            x_coordinate = []\n",
    "            y_coordinate = []\n",
    "            z_coordinate = []\n",
    "            stimuliFamilarity = []\n",
    "            dataQuality =[]\n",
    "            recData = []\n",
    "            recID   = []\n",
    "            cellID  = []\n",
    "\n",
    "            if len(imData)>0:\n",
    "               imStats = imData['stat']\n",
    "               for idx, cell_flu in enumerate(flu): # from suite2p website: med: (y,x) center of cell\n",
    "                  x_coordinate += [np.round(imStats[idx]['med'][1] *512/558.9) + info.recordingList['x-coordinate'] [ind]]\n",
    "                  y_coordinate += [np.round(imStats[idx]['med'][0] *512/558.9) + info.recordingList['y-coordinate'] [ind]]\n",
    "                  z_coordinate += [info.recordingList['z-coordinate'] [ind]]\n",
    "                  animalID     += [info.recordingList['animalID'] [ind]]\n",
    "                  stimuliFamilarity += [info.recordingList['stimuliFamiliarity'] [ind]]\n",
    "                  dataQuality  += [info.recordingList['dataQuality'] [ind]]\n",
    "                  recData  += [info.recordingList['recordingDate'] [ind]]\n",
    "                  recID    += [info.recordingList['recordingID'] [ind]]\n",
    "                  cellID   += [idx]\n",
    "            else:\n",
    "               x_coordinate = [np.nan]\n",
    "               y_coordinate = [np.nan]\n",
    "               z_coordinate = [np.nan]\n",
    "               animalID     = [info.recordingList['animalID'] [ind]]\n",
    "               stimuliFamilarity = [info.recordingList['stimuliFamiliarity'] [ind]]\n",
    "               dataQuality  = [info.recordingList['dataQuality'] [ind]]\n",
    "               recData  = [info.recordingList['recordingDate'] [ind]]\n",
    "               recID    = [info.recordingList['recordingID'] [ind]]\n",
    "               cellID   = [np.nan]\n",
    "\n",
    "            #save outputs for population analysis\n",
    "            savename = info.recordingList.analysispathname[ind] + 'extracted_variables.pkl'\n",
    "            with open(savename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "               pickle.dump([trialStartTimes, trialTypes, pvals, dffTrace, \n",
    "                           dffTrace_mean, dffAfterStim1500ms_mean,\n",
    "                           x_coordinate,y_coordinate,z_coordinate,\n",
    "                           animalID,stimuliFamilarity,pvalsWilcoxon, dataQuality,\n",
    "                           recData, recID, cellID, pupilTrace, pupilTrace_mean, \n",
    "                           pupilQualityh, pupilTraceVer, pupilTrace_meanVer, pupilQualityv,\n",
    "                           dffTrace_normalised,dffTrace_mean_normalised, dffTrace_median], f)\n",
    "            info.recordingList.loc[ind,'extractedVar'] = 1\n",
    "         else:\n",
    "            print('FAILED: no paq file : ' + pathname)\n",
    "            info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "      except:\n",
    "         print('FAILED: ' + pathname)\n",
    "         info.recordingList.loc[ind,'extractedVar'] = 0\n",
    "\n",
    "#save info \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-extracted.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump(info, f)\n",
    "print('All should be done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST CODE ONE RECORDING \n",
    "# ind = 1\n",
    "# savepathname = info.recordingList.analysispathname[ind]\n",
    "# filenamePAQ_analysis = [f for f in glob.glob(savepathname + '2extracted_variables.pkl')] # paq analysis file\n",
    "# if (len(filenamePAQ_analysis)==1):\n",
    "#     info.recordingList.loc[ind,'extractedVar'] = 1\n",
    "# else:\n",
    "#     print(str(ind) + ': Creating: ' + info.recordingList.analysispathname[ind])\n",
    "#     #Create a huge dictionary with all cells and parameters for each cell\n",
    "#     pathname = info.recordingList.analysispathname[ind]\n",
    "#     print('Creating the dict for:' + pathname)\n",
    "\n",
    "#     ########## Organise stimuli times \n",
    "#     if  (info.recordingList.paqExtraction[ind] ==1):\n",
    "#         paqData = pd.read_pickle (pathname+'paq-data.pkl')\n",
    "#         paqRate = paqData['rate']\n",
    "#         # Get the stim start times \n",
    "#         frame_clock    = utils.paq_data (paqData, 'prairieFrame', threshold_ttl=True, plot=False)\n",
    "#         optoStimTimes  = utils.paq_data (paqData, 'optoLoopback', threshold_ttl=True, plot=False)\n",
    "#         if len(optoStimTimes)>500:\n",
    "#             # the frame_clock is slightly longer in paq as there are some up to a sec delay from\n",
    "#             # microscope to PAQI/O software.  \n",
    "#             optoStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='optoLoopback',\n",
    "#                                                 frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "#             visStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='maskerLED',\n",
    "#                                                 frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "#             shutterTimes = utils.shutter_start_frame (paq=paqData, stim_chan_name='shutterLoopback',\n",
    "#                                                 frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "\n",
    "#             # Lets organise it more for analysis friendly format\n",
    "#             trialStartTimes = np.unique(np.concatenate((optoStimTimes,visStimTimes),0))\n",
    "#             trialTypes = []\n",
    "#             for t in trialStartTimes:\n",
    "#                 optoexist =  np.any(optoStimTimes== t)\n",
    "#                 visexist  =  np.any( visStimTimes == t)\n",
    "#                 if  optoexist  & visexist: \n",
    "#                     trialTypes += ['Both']\n",
    "#                 elif optoexist &~ visexist:\n",
    "#                     trialTypes += ['onlyOpto']\n",
    "#                 elif ~optoexist & visexist:\n",
    "#                     trialTypes += ['onlyVis']\n",
    "#                 else:\n",
    "#                     trialTypes += ['CHECK']\n",
    "#             trialStartTimes = shutterTimes\n",
    "#         #t = [idx for idx, t_type in enumerate(trialTypes) if t_type=='Both']\n",
    "\n",
    "#         ########## Organise calcium imaging traces \n",
    "#         pvals ={} \n",
    "#         pvalsWilcoxon = {}\n",
    "#         dffTrace ={} \n",
    "#         dffTrace_mean ={}\n",
    "#         dffTrace_normalised ={} \n",
    "#         dffTrace_mean_normalised ={}\n",
    "        \n",
    "        \n",
    "#         if (info.recordingList.dffExtraction[ind] ==1):\n",
    "#             imData = pd.read_pickle (pathname +'imaging-data.pkl')\n",
    "#             fluR      = imData['flu']\n",
    "#             n_frames  = imData['n_frames']\n",
    "#             flu_raw   = imData['flu_raw']\n",
    "\n",
    "#             # Lets put nans for stimulated frames\n",
    "#             frameTimes = np.full((1,fluR.shape[1] ), False) # create a full false array\n",
    "#             for sT in shutterTimes:\n",
    "#                 frameTimes[:,sT:(sT+shutterLength)] = True\n",
    "#             fluR[:, frameTimes[0,:]] = np.nan\n",
    "\n",
    "#             # clean detrended traces\n",
    "#             flu = utils.clean_traces(fluR)\n",
    "#             flu_normalised = mfun.norm_to_zero_one (flu)\n",
    "\n",
    "#             ### Look for responsiveness for 4 trial types\n",
    "#             for t in tTypes:\n",
    "#                 if t =='All':\n",
    "#                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "#                 else:\n",
    "#                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                \n",
    "#                 if len(trialInd)>1:\n",
    "#                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "#                                                             post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "#                                                             testType ='ttest')\n",
    "#                     pvals[t] = pval\n",
    "#                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "#                                                             post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "#                                                             testType ='wilcoxon')\n",
    "#                     pvalsWilcoxon[t] = pval\n",
    "\n",
    "#             ### Get dff values for 4 trial types\n",
    "#             for indx, t in enumerate(tTypes) :\n",
    "#                 if t =='All':\n",
    "#                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "#                 else:\n",
    "#                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                \n",
    "#                 if len(trialInd)>1:\n",
    "#                     dffTrace[t]      = utils.flu_splitter(flu, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "#                     dffTrace_mean[t] = np.mean(dffTrace[t],2) # Cell x time\n",
    "#                     dffTrace_normalised[t]      = utils.flu_splitter(flu_normalised, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "#                     dffTrace_mean_normalised[t] = np.mean(dffTrace_normalised[t],2) # Cell x time\n",
    "\n",
    "#         ########## Organise pupil  traces \n",
    "#         pupilTrace = {}\n",
    "#         if (info.recordingList.dffExtraction[ind] ==1): \n",
    "#             pupilData = pd.read_pickle (pathname +'pupil-data.pkl')\n",
    "#             pupilraw = pupilData['verticalDis']\n",
    "#             pupilraw = utils.clean_traces(pupilraw)\n",
    "\n",
    "#             for indx, t in enumerate(tTypes) :\n",
    "#                 if t =='All':\n",
    "#                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "#                 else:\n",
    "#                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type==t]\n",
    "                \n",
    "#                 if len(trialInd)>1:\n",
    "#                     pupilTrace[t]  = utils.trace_splitter(pupilraw,trialStartTimes[trialInd], pre_frames, post_frames)\n",
    "            \n",
    "            \n",
    "#             # #create dff for all cells\n",
    "#             # for indC, cell_dff in enumerate(flu):\n",
    "#             #    plotTrue = False\n",
    "#             #    if (len(optoStimTimes)==40): \n",
    "#             #       tTypes = ['Both', 'onlyOpto', 'onlyVis']\n",
    "#             #       plotTrue =  (pvals['onlyVis'][indC] < 1e-6) or (pvals['onlyOpto'][indC] < 1e-6) or (pvals['Both'][indC] < 1e-6)\n",
    "#             #    elif (len(optoStimTimes)==20):\n",
    "#             #       tTypes = ['Both', 'onlyVis']\n",
    "#             #       plotTrue =  (pvals['onlyVis'][indC] < 1e-6)  or (pvals['Both'][indC] < 1e-6)\n",
    "\n",
    "#             #    if plotTrue:\n",
    "#             #       fig = plt.figure(str(indC))\n",
    "#             #       plt.switch_backend('Agg')\n",
    "#             #       for indx, t in enumerate(tTypes):\n",
    "#             #             pfun.lineplot_withSEM (data=dffTrace[t][indC], colorInd = indx, label=t)\n",
    "#             #             pfun.save_figure(pathname[-21:-1]+'_DFF_mean_'+str(indC),info.figsPath+'\\\\cellDFF\\\\')\n",
    "#             #             plt.close(fig)\n",
    "\n",
    "#         #lets get recording info\n",
    "#         animalID = []\n",
    "#         x_coordinate = []\n",
    "#         y_coordinate = []\n",
    "#         z_coordinate = []\n",
    "#         stimuliFamilarity = []\n",
    "#         dataQuality =[]\n",
    "#         recData = []\n",
    "#         recID   = []\n",
    "#         cellID  = []\n",
    "#         imStats = imData['stat']\n",
    "#         for idx, cell_flu in enumerate(flu): # from suite2p website: med: (y,x) center of cell\n",
    "#             x_coordinate += [np.round(imStats[idx]['med'][1] *512/558.9) + info.recordingList['x-coordinate'] [ind]]\n",
    "#             y_coordinate += [np.round(imStats[idx]['med'][0] *512/558.9) + info.recordingList['y-coordinate'] [ind]]\n",
    "#             z_coordinate += [info.recordingList['z-coordinate'] [ind]]\n",
    "#             animalID     += [info.recordingList['animalID'] [ind]]\n",
    "#             stimuliFamilarity += [info.recordingList['stimuliFamiliarity'] [ind]]\n",
    "#             dataQuality  += [info.recordingList['dataQuality'] [ind]]\n",
    "#             recData  += [info.recordingList['recordingDate'] [ind]]\n",
    "#             recID    += [info.recordingList['recordingID'] [ind]]\n",
    "#             cellID   += [idx]\n",
    "\n",
    "\n",
    "#         #save outputs for population analysis\n",
    "#         savename = info.recordingList.analysispathname[ind] + 'extracted_variables.pkl'\n",
    "#         with open(savename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#             pickle.dump([trialStartTimes, trialTypes, pvals, dffTrace, \n",
    "#                         dffTrace_mean, dffTrace_mean_normalised,\n",
    "#                         x_coordinate,y_coordinate,z_coordinate,\n",
    "#                         animalID,stimuliFamilarity,pvalsWilcoxon, dataQuality,\n",
    "#                         recData, recID, cellID,pupilTrace, dffTrace_normalised], f)\n",
    "#         info.recordingList.loc[ind,'extractedVar'] = 1\n",
    "#     else:\n",
    "#         print('FAILED: no paq file : ' + pathname)\n",
    "#         info.recordingList.loc[ind,'extractedVar'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge all datapoints & save them in a dictionary\n",
    "\n",
    "infoPath = 'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\infoForAnalysis-extracted.pkl'\n",
    "\n",
    "info = pd.read_pickle(infoPath)\n",
    "info.recordingList.loc[318,'extractedVar'] = 0 # weird paq file -excluded.\n",
    "\n",
    "\n",
    "pvalsBoth = []\n",
    "pvalsVis = []\n",
    "pvalsOpto = []\n",
    "tTypes = ['All','Both', 'onlyOpto', 'onlyVis']\n",
    "\n",
    "animalID = []\n",
    "x_coordinate = []\n",
    "y_coordinate = []\n",
    "z_coordinate = []\n",
    "stimuliFamilarity = []\n",
    "dataQuality  = []\n",
    "\n",
    "dff_meanBothValue  = []\n",
    "dff_meanVisValue  = []\n",
    "dff_meanOptoValue  = []\n",
    "\n",
    "dff_BothValue_median  = []\n",
    "dff_VisValue_median  = []\n",
    "dff_OptoValue_median  = []\n",
    "\n",
    "dff_meanBothValue_normalised  = []\n",
    "dff_meanVisValue_normalised   = []\n",
    "dff_meanOptoValue_normalised  = []\n",
    "\n",
    "recData = []\n",
    "recID   = []\n",
    "cellID  = []\n",
    "pupilID = []\n",
    "\n",
    "pupil_resample_num = int(6*5)\n",
    "\n",
    "\n",
    "\n",
    "# Create the main variables for plots by merging the extracted variables from all recordings\n",
    "ty = 0\n",
    "indPupil = 0\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "   if (info.recordingList.extractedVar[ind] ==1):\n",
    "      # load the extracted values\n",
    "      pathname = info.recordingList.analysispathname[ind] \n",
    "      extData = pd.read_pickle (pathname + 'extracted_variables.pkl')\n",
    "      print('Extraction started for : ' + str(ind))\n",
    "      len_cellID   = len(extData[15])\n",
    "\n",
    "      # Get Dff traces MEAN\n",
    "      dff_trace = extData[4] #4 for mean, 24 for median\n",
    "      if len(dff_trace)>2:\n",
    "         print('Organising DFF')\n",
    "         if ind == 0: # For the first recording\n",
    "            dff_traceBoth = dff_trace['Both']\n",
    "            dff_traceVis  = dff_trace['onlyVis']\n",
    "            if 'onlyOpto' in dff_trace:\n",
    "               dff_traceOpto = dff_trace['onlyOpto']\n",
    "            else:\n",
    "               fakeOpto = np.empty (np.shape(dff_trace['Both']))\n",
    "               fakeOpto[:] = np.nan\n",
    "               dff_traceOpto = fakeOpto\n",
    "         else:\n",
    "            dff_traceBoth =  np.vstack ((dff_traceBoth , dff_trace['Both']))\n",
    "            dff_traceVis  =  np.vstack ((dff_traceVis  , dff_trace['onlyVis']))\n",
    "            \n",
    "            if 'onlyOpto' in dff_trace:\n",
    "               dff_traceOpto =  np.vstack ((dff_traceOpto , dff_trace['onlyOpto']))\n",
    "            else:\n",
    "               fakeOpto = np.empty (np.shape(dff_trace['Both']))\n",
    "               fakeOpto[:] = np.nan\n",
    "               dff_traceOpto =  np.vstack ((dff_traceOpto ,fakeOpto))\n",
    "      else:\n",
    "          empty_array_shape = (len_cellID,240)\n",
    "          if ind == 0:\n",
    "            dff_traceVis  = np.empty (empty_array_shape)\n",
    "            dff_traceBoth = np.empty (empty_array_shape)\n",
    "            dff_traceOpto = np.empty (empty_array_shape)\n",
    "\n",
    "          else:\n",
    "            dff_traceVis  = np.vstack ((dff_traceVis , np.empty (empty_array_shape)))\n",
    "            dff_traceBoth = np.vstack ((dff_traceBoth , np.empty (empty_array_shape)))\n",
    "            dff_traceOpto = np.vstack ((dff_traceOpto , np.empty (empty_array_shape)))\n",
    "\n",
    "      # Get Dff traces MEDIAN \n",
    "      dff_trace = extData[24] #4 for mean, 24 for median\n",
    "      if len(dff_trace)>2:\n",
    "         print('Organising DFF')\n",
    "         if ind == 0: # For the first recording\n",
    "            dff_traceBoth_median = dff_trace['Both']\n",
    "            dff_traceVis_median  = dff_trace['onlyVis']\n",
    "            if 'onlyOpto' in dff_trace:\n",
    "               dff_traceOpto_median = dff_trace['onlyOpto']\n",
    "            else:\n",
    "               fakeOpto = np.empty (np.shape(dff_trace['Both']))\n",
    "               fakeOpto[:] = np.nan\n",
    "               dff_traceOpto_median = fakeOpto\n",
    "         else:\n",
    "            dff_traceBoth_median =  np.vstack ((dff_traceBoth_median , dff_trace['Both']))\n",
    "            dff_traceVis_median  =  np.vstack ((dff_traceVis_median  , dff_trace['onlyVis']))\n",
    "            \n",
    "            if 'onlyOpto' in dff_trace:\n",
    "               dff_traceOpto_median =  np.vstack ((dff_traceOpto_median , dff_trace['onlyOpto']))\n",
    "            else:\n",
    "               fakeOpto_median = np.empty (np.shape(dff_trace['Both']))\n",
    "               fakeOpto[:] = np.nan\n",
    "               dff_traceOpto_median =  np.vstack ((dff_traceOpto_median ,fakeOpto))\n",
    "      else:\n",
    "          empty_array_shape = (len_cellID,240)\n",
    "          if ind == 0:\n",
    "            dff_traceVis_median  = np.empty (empty_array_shape)\n",
    "            dff_traceBoth_median = np.empty (empty_array_shape)\n",
    "            dff_traceOpto_median = np.empty (empty_array_shape)\n",
    "\n",
    "          else:\n",
    "            dff_traceVis_median  = np.vstack ((dff_traceVis_median , np.empty (empty_array_shape)))\n",
    "            dff_traceBoth_median = np.vstack ((dff_traceBoth_median , np.empty (empty_array_shape)))\n",
    "            dff_traceOpto_median = np.vstack ((dff_traceOpto_median , np.empty (empty_array_shape)))\n",
    "\n",
    "      # Get Dff traces - Normalised\n",
    "      dff_trace = extData[23]\n",
    "      if len(dff_trace)>2:\n",
    "         print('Organising DFF normalised')\n",
    "         if ind == 0: # For the first recording\n",
    "            dff_traceBoth_normalised = dff_trace['Both']\n",
    "            dff_traceVis_normalised  = dff_trace['onlyVis']\n",
    "            if 'onlyOpto' in dff_trace:\n",
    "               dff_traceOpto_normalised = dff_trace['onlyOpto']\n",
    "            else:\n",
    "               fakeOpto = np.empty (np.shape(dff_trace['Both']))\n",
    "               fakeOpto[:] = np.nan\n",
    "               dff_traceOpto_normalised = fakeOpto\n",
    "         else:\n",
    "            dff_traceBoth_normalised =  np.vstack ((dff_traceBoth_normalised , dff_trace['Both']))\n",
    "            dff_traceVis_normalised  =  np.vstack ((dff_traceVis_normalised  , dff_trace['onlyVis']))\n",
    "            \n",
    "            if 'onlyOpto' in dff_trace:\n",
    "               dff_traceOpto_normalised =  np.vstack ((dff_traceOpto_normalised , dff_trace['onlyOpto']))\n",
    "            else:\n",
    "               fakeOpto = np.empty (np.shape(dff_trace['Both']))\n",
    "               fakeOpto[:] = np.nan\n",
    "               dff_traceOpto_normalised =  np.vstack ((dff_traceOpto_normalised ,fakeOpto))\n",
    "      else:\n",
    "          empty_array_shape = (len_cellID,240)\n",
    "          if ind == 0:\n",
    "            dff_traceVis_normalised  = np.empty (empty_array_shape)\n",
    "            dff_traceBoth_normalised = np.empty (empty_array_shape)\n",
    "            dff_traceOpto_normalised = np.empty (empty_array_shape)\n",
    "\n",
    "          else:\n",
    "            dff_traceVis_normalised  = np.vstack ((dff_traceVis_normalised , np.empty (empty_array_shape)))\n",
    "            dff_traceBoth_normalised = np.vstack ((dff_traceBoth_normalised , np.empty (empty_array_shape)))\n",
    "            dff_traceOpto_normalised = np.vstack ((dff_traceOpto_normalised , np.empty (empty_array_shape)))\n",
    "      \n",
    "      # Get pupil traces\n",
    "      pupil_trace = extData[17]\n",
    "      pupilQuality = extData[18]\n",
    "   \n",
    "      if len_cellID==0:\n",
    "         len_cellID=1\n",
    "      if indPupil == 0: # For the first recording\n",
    "         indPupil = 1\n",
    "         if (len(pupil_trace) >0) & (pupilQuality>0.75):\n",
    "            print('Organising Pupil traces for the first time')\n",
    "            pupilID.extend([1]*len_cellID)\n",
    "            pupil_traceBoth = np.tile(pupil_trace['Both'],(len_cellID,1))\n",
    "            pupil_traceVis  = np.tile(pupil_trace['onlyVis'],(len_cellID,1)) \n",
    "            if 'onlyOpto' in pupil_trace:\n",
    "               pupil_traceOpto = np.tile(pupil_trace['onlyOpto'],(len_cellID,1)) \n",
    "            else:\n",
    "               fakeOpto = np.empty(np.tile(pupil_trace['Both'],(len_cellID,1)).shape)\n",
    "               fakeOpto[:] = np.nan\n",
    "               pupil_traceOpto = fakeOpto\n",
    "         else:\n",
    "            pupilID.extend([0]*len_cellID)\n",
    "            fake = np.empty ((len_cellID,240))\n",
    "            fake[:] = np.nan\n",
    "            pupil_traceBoth = fake\n",
    "            pupil_traceVis  = fake\n",
    "            pupil_traceOpto =  fake\n",
    "      else:\n",
    "         if (len(pupil_trace) >0) & (pupilQuality>0.75):\n",
    "            print('Organising Pupil traces for  followed recordings')\n",
    "            pupilID.extend([1]*len_cellID)\n",
    "            pupil_traceBoth =  np.vstack ((pupil_traceBoth, (np.tile(pupil_trace['Both'],(len_cellID,1)))))\n",
    "            pupil_traceVis  =  np.vstack ((pupil_traceVis, np.tile(pupil_trace['onlyVis'],(len_cellID,1))))\n",
    "            if 'onlyOpto' in pupil_trace:\n",
    "               pupil_traceOpto =  np.vstack ((pupil_traceOpto,np.tile(pupil_trace['onlyOpto'],(len_cellID,1))))\n",
    "            else:\n",
    "               fakeOpto = np.empty (np.tile(pupil_trace['Both'],(len_cellID,1)).shape)\n",
    "               fakeOpto[:] = np.nan\n",
    "               pupil_traceOpto =  np.vstack ((pupil_traceOpto ,fakeOpto))\n",
    "         else:\n",
    "            pupilID.extend([0]*len_cellID)\n",
    "            fake = np.empty ((len_cellID,240))\n",
    "            fake[:] = np.nan\n",
    "            pupil_traceBoth = np.vstack ((pupil_traceBoth , fake))\n",
    "            pupil_traceVis  = np.vstack ((pupil_traceVis  , fake))\n",
    "            pupil_traceOpto = np.vstack ((pupil_traceOpto , fake))\n",
    "         \n",
    "      # Get p vals for all cells\n",
    "      pvals = extData[2]\n",
    "      if len(pvals)>0:\n",
    "         pvalsBoth += pvals['Both'].tolist()\n",
    "         pvalsVis  += pvals['onlyVis'].tolist()\n",
    "\n",
    "         if 'onlyOpto' in dff_trace:\n",
    "            pvalsOpto  += pvals['onlyOpto'].tolist()\n",
    "         else:\n",
    "            fakeOpto = np.empty (np.shape(pvals['Both']))\n",
    "            fakeOpto[:] = 5\n",
    "            pvalsOpto  += fakeOpto.tolist()\n",
    "      else:\n",
    "         pvalsBoth += [5]\n",
    "         pvalsVis  += [5]\n",
    "         pvalsOpto += [5]\n",
    "\n",
    "      # get dff mean values for analysis window \n",
    "      dff_mean = extData[5] # mean 1500ms \n",
    "      if len(dff_mean)>0:\n",
    "         print('Adding dff mean')\n",
    "         print(len(dff_mean['Both'].tolist()))\n",
    "         dff_meanBothValue += dff_mean['Both'].tolist()\n",
    "         dff_meanVisValue  += dff_mean['onlyVis'].tolist()\n",
    "\n",
    "         if 'onlyOpto' in dff_trace:\n",
    "            dff_meanOptoValue += dff_mean['onlyOpto'].tolist()\n",
    "         else:\n",
    "            fakeOpto = np.empty (np.shape(dff_mean['Both']))\n",
    "            fakeOpto[:]   = np.nan\n",
    "            dff_meanOptoValue  += fakeOpto.tolist()\n",
    "      else:\n",
    "         fakeOpto = np.empty(1)\n",
    "         fakeOpto[:]   = np.nan\n",
    "         dff_meanBothValue += fakeOpto.tolist()\n",
    "         dff_meanVisValue  += fakeOpto.tolist()\n",
    "         dff_meanOptoValue += fakeOpto.tolist()\n",
    "\n",
    "\n",
    "      # get the necessary info about cells \n",
    "      x_coordinate += extData[6]\n",
    "      y_coordinate += extData[7]\n",
    "      z_coordinate += extData[8]\n",
    "      animalID     += extData[9]\n",
    "      stimuliFamilarity += extData[10]\n",
    "      dataQuality += extData[12]\n",
    "      recData  += extData[13]\n",
    "      recID    += extData[14]\n",
    "      cellID   += extData[15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organise & save files\n",
    "\n",
    "fRate = 1000/30.0\n",
    "pre_frames    = 2000.0# in ms\n",
    "pre_frames    = int(np.ceil(pre_frames/fRate))\n",
    "post_frames   = 6000.0 # in ms\n",
    "post_frames   = int(np.ceil(post_frames/fRate))\n",
    "analysis_time = 1500.0 # in ms\n",
    "analysis_time = int(np.ceil(analysis_time/fRate))\n",
    "simulationDur_ms = 350.0 # in ms\n",
    "simulationDur = int(np.ceil(simulationDur_ms/fRate))\n",
    "### Lets do tiny cleaning for imaging traces\n",
    "ac = np.median(dff_traceVis[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(dff_traceVis)[1],1)).transpose()\n",
    "dff_traceVis_normalisedtopre = dff_traceVis -ac\n",
    "\n",
    "ac = np.median(dff_traceOpto[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(dff_traceOpto)[1],1)).transpose()\n",
    "dff_traceOpto_normalisedtopre= dff_traceOpto -ac\n",
    "\n",
    "ac = np.median(dff_traceBoth[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(dff_traceBoth)[1],1)).transpose()\n",
    "dff_traceBoth_normalisedtopre = dff_traceBoth -ac\n",
    "\n",
    "### Lets do tiny cleaning for imaging traces -MEDIAN\n",
    "ac = np.median(dff_traceVis_median[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(dff_traceVis_median)[1],1)).transpose()\n",
    "dff_traceVis_normalisedtopre_median = dff_traceVis_median -ac\n",
    "\n",
    "ac = np.median(dff_traceOpto_median[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(dff_traceOpto_median)[1],1)).transpose()\n",
    "dff_traceOpto_normalisedtopre_median = dff_traceOpto_median -ac\n",
    "\n",
    "ac = np.median(dff_traceBoth[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(dff_traceBoth)[1],1)).transpose()\n",
    "dff_traceBoth_normalisedtopre_median = dff_traceBoth -ac\n",
    "                 \n",
    "# ### Lets do tiny cleaning for imaging traces\n",
    "# ac = np.mean(dff_traceBoth_normalised[:, 0:pre_frames],1)\n",
    "# ac = np.tile(ac,(np.shape(dff_traceBoth_normalised)[1],1)).transpose()\n",
    "# dff_traceBoth_normalised = dff_traceBoth_normalised -ac\n",
    "\n",
    "# ac = np.mean(dff_traceVis_normalised[:, 0:pre_frames],1)\n",
    "# ac = np.tile(ac,(np.shape(dff_traceVis_normalised)[1],1)).transpose()\n",
    "# dff_traceVis_normalised = dff_traceVis_normalised -ac\n",
    "\n",
    "# ac = np.mean(dff_traceOpto_normalised[:, 0:pre_frames],1)\n",
    "# ac = np.tile(ac,(np.shape(dff_traceOpto_normalised)[1],1)).transpose()\n",
    "# dff_traceOpto_normalised = dff_traceOpto_normalised -ac\n",
    "\n",
    "### Lets do tiny cleaning for pupil traces\n",
    "ac = np.median(pupil_traceBoth[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(pupil_traceBoth)[1],1)).transpose()\n",
    "pupil_traceBoth = pupil_traceBoth -ac\n",
    "\n",
    "ac = np.median(pupil_traceVis[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(pupil_traceVis)[1],1)).transpose()\n",
    "pupil_traceVis = pupil_traceVis -ac\n",
    "\n",
    "ac = np.median(pupil_traceOpto[:, 0:pre_frames],1)\n",
    "ac = np.tile(ac,(np.shape(pupil_traceOpto)[1],1)).transpose()\n",
    "pupil_traceOpto = pupil_traceOpto -ac\n",
    "\n",
    "pupil_traceOpto = resample(pupil_traceOpto, pupil_resample_num, axis=1)\n",
    "pupil_traceVis = resample(pupil_traceVis, pupil_resample_num, axis=1)\n",
    "pupil_traceBoth = resample(pupil_traceBoth, pupil_resample_num, axis=1)\n",
    "\n",
    "dff_meanBoth1sec = np.nanmean(dff_traceBoth [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1)\n",
    "dff_meanVis1sec  = np.nanmean(dff_traceVis  [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1)\n",
    "dff_meanOpto1sec = np.nanmean(dff_traceOpto [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1) \n",
    "\n",
    "\n",
    "zdff_traceBoth = stats.zscore (dff_traceBoth, nan_policy='omit')\n",
    "zdff_traceVis  = stats.zscore (dff_traceVis, nan_policy='omit')\n",
    "zdff_traceOpto = stats.zscore (dff_traceOpto, nan_policy='omit')\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForSelectingInterestedCells.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((animalID, stimuliFamilarity, dataQuality,\n",
    "                 recData, recID, cellID, \n",
    "                 pvalsBoth, pvalsVis, pvalsOpto,\n",
    "                 dff_meanVisValue, dff_meanBothValue, \n",
    "                 dff_meanOptoValue, pupilID),f)\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth, dff_traceVis, dff_traceOpto), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_median.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_median, dff_traceVis_median, dff_traceOpto_median), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_normalised.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalised, dff_traceVis_normalised, dff_traceOpto_normalised), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_normalisedtoPre.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalisedtopre, dff_traceVis_normalisedtopre, dff_traceOpto_normalisedtopre), f)\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_normalisedtoPre_median.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalisedtopre_median, dff_traceVis_normalisedtopre_median, dff_traceOpto_normalisedtopre_median), f)\n",
    "\n",
    "\n",
    "    \n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_position.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((x_coordinate, y_coordinate, z_coordinate ), f)\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlottingPupil.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((pupil_traceVis, pupil_traceBoth, pupil_traceOpto ), f)\n",
    "print('All should be done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: clapfcstimulation\n",
      "Extraction started for: 0\n",
      "Extraction started for: 1\n",
      "Extraction started for: 2\n",
      "Extraction started for: 3\n",
      "Extraction started for: 4\n",
      "Extraction started for: 5\n",
      "Extraction started for: 6\n",
      "Extraction started for: 7\n",
      "Extraction started for: 8\n",
      "Extraction started for: 9\n",
      "Extraction started for: 10\n",
      "Extraction started for: 11\n",
      "Extraction started for: 12\n",
      "Extraction started for: 13\n",
      "Extraction started for: 14\n",
      "Extraction started for: 15\n",
      "Extraction started for: 16\n",
      "Extraction started for: 17\n",
      "Extraction started for: 18\n",
      "Extraction started for: 19\n",
      "Extraction started for: 20\n",
      "Extraction started for: 21\n",
      "Extraction started for: 22\n",
      "Extraction started for: 23\n",
      "Extraction started for: 24\n",
      "Extraction started for: 25\n",
      "Extraction started for: 26\n",
      "Extraction started for: 27\n",
      "Extraction started for: 28\n",
      "Extraction started for: 29\n",
      "Extraction started for: 30\n",
      "Extraction started for: 31\n",
      "Extraction started for: 32\n",
      "Extraction started for: 33\n",
      "Extraction started for: 34\n",
      "Extraction started for: 35\n",
      "Extraction started for: 36\n",
      "Extraction started for: 37\n",
      "Extraction started for: 38\n",
      "Extraction started for: 39\n",
      "Extraction started for: 40\n",
      "Extraction started for: 41\n",
      "Extraction started for: 42\n",
      "Extraction started for: 43\n",
      "Extraction started for: 44\n",
      "Extraction started for: 45\n",
      "Extraction started for: 46\n",
      "Extraction started for: 47\n",
      "Extraction started for: 48\n",
      "Extraction started for: 49\n",
      "Extraction started for: 50\n",
      "Extraction started for: 51\n",
      "Extraction started for: 52\n",
      "Extraction started for: 53\n",
      "Extraction started for: 54\n",
      "Extraction started for: 55\n",
      "Extraction started for: 56\n",
      "Extraction started for: 57\n",
      "Extraction started for: 58\n",
      "Extraction started for: 59\n",
      "Extraction started for: 60\n",
      "Extraction started for: 61\n",
      "Extraction started for: 62\n",
      "Extraction started for: 63\n",
      "Extraction started for: 64\n",
      "Extraction started for: 65\n",
      "Extraction started for: 66\n",
      "Extraction started for: 67\n",
      "Extraction started for: 68\n",
      "Extraction started for: 69\n",
      "Extraction started for: 70\n",
      "Extraction started for: 71\n",
      "Extraction started for: 72\n",
      "Extraction started for: 73\n",
      "Extraction started for: 74\n",
      "Extraction started for: 75\n",
      "Extraction started for: 76\n",
      "Extraction started for: 77\n",
      "Extraction started for: 78\n",
      "Extraction started for: 79\n",
      "Extraction started for: 80\n",
      "Extraction started for: 81\n",
      "Extraction started for: 82\n",
      "Extraction started for: 83\n",
      "Extraction started for: 84\n",
      "Extraction started for: 85\n",
      "Extraction started for: 86\n",
      "Extraction started for: 87\n",
      "Extraction started for: 88\n",
      "Extraction started for: 89\n",
      "Extraction started for: 90\n",
      "Extraction started for: 91\n",
      "Extraction started for: 92\n",
      "Extraction started for: 93\n",
      "Extraction started for: 94\n",
      "Extraction started for: 95\n",
      "Extraction started for: 96\n",
      "Extraction started for: 97\n",
      "Extraction started for: 98\n",
      "Extraction started for: 99\n",
      "Extraction started for: 100\n",
      "Extraction started for: 101\n",
      "Extraction started for: 102\n",
      "Extraction started for: 103\n",
      "Extraction started for: 104\n",
      "Extraction started for: 105\n",
      "Extraction started for: 106\n",
      "Extraction started for: 107\n",
      "Extraction started for: 108\n",
      "Extraction started for: 109\n",
      "Extraction started for: 110\n",
      "Extraction started for: 111\n",
      "Extraction started for: 112\n",
      "Extraction started for: 113\n",
      "Extraction started for: 114\n",
      "Extraction started for: 115\n",
      "Extraction started for: 116\n",
      "Extraction started for: 117\n",
      "Extraction started for: 118\n",
      "Extraction started for: 119\n",
      "Extraction started for: 120\n",
      "Extraction started for: 121\n",
      "Extraction started for: 122\n",
      "Extraction started for: 123\n",
      "Extraction started for: 124\n",
      "Extraction started for: 125\n",
      "Extraction started for: 126\n",
      "Extraction started for: 127\n",
      "Extraction started for: 128\n",
      "Extraction started for: 129\n",
      "Extraction started for: 130\n",
      "Extraction started for: 131\n",
      "Extraction started for: 132\n",
      "Extraction started for: 133\n",
      "Extraction started for: 134\n",
      "Extraction started for: 135\n",
      "Extraction started for: 136\n",
      "Extraction started for: 137\n",
      "Extraction started for: 138\n",
      "Extraction started for: 139\n",
      "Extraction started for: 140\n",
      "Extraction started for: 141\n",
      "Extraction started for: 142\n",
      "Extraction started for: 143\n",
      "Extraction started for: 144\n",
      "Extraction started for: 145\n",
      "Extraction started for: 146\n",
      "Extraction started for: 147\n",
      "Extraction started for: 148\n",
      "Extraction started for: 149\n",
      "Extraction started for: 150\n",
      "Extraction started for: 151\n",
      "Extraction started for: 153\n",
      "Extraction started for: 154\n",
      "Extraction started for: 155\n",
      "Extraction started for: 156\n",
      "Extraction started for: 157\n",
      "Extraction started for: 158\n",
      "Extraction started for: 159\n",
      "Extraction started for: 160\n",
      "Extraction started for: 161\n",
      "Extraction started for: 162\n",
      "Extraction started for: 163\n",
      "Extraction started for: 164\n",
      "Extraction started for: 165\n",
      "Extraction started for: 168\n",
      "Extraction started for: 169\n",
      "Extraction started for: 170\n",
      "Extraction started for: 171\n",
      "Extraction started for: 172\n",
      "Extraction started for: 173\n",
      "Extraction started for: 174\n",
      "Extraction started for: 175\n",
      "Extraction started for: 176\n",
      "Extraction started for: 177\n",
      "Extraction started for: 179\n",
      "Extraction started for: 180\n",
      "Extraction started for: 181\n",
      "Extraction started for: 182\n",
      "Extraction started for: 265\n",
      "Extraction started for: 266\n",
      "Extraction started for: 267\n",
      "Extraction started for: 268\n",
      "Extraction started for: 269\n",
      "Extraction started for: 270\n",
      "Extraction started for: 271\n",
      "Extraction started for: 272\n",
      "Extraction started for: 273\n",
      "Extraction started for: 274\n",
      "Extraction started for: 275\n",
      "Extraction started for: 276\n",
      "Extraction started for: 277\n",
      "Extraction started for: 278\n",
      "Extraction started for: 279\n",
      "Extraction started for: 280\n",
      "Extraction started for: 281\n",
      "Extraction started for: 282\n",
      "Extraction started for: 283\n",
      "Extraction started for: 284\n",
      "Extraction started for: 285\n",
      "Extraction started for: 286\n",
      "Extraction started for: 287\n",
      "Extraction started for: 288\n",
      "Extraction started for: 289\n",
      "Extraction started for: 290\n",
      "Extraction started for: 291\n",
      "Extraction started for: 292\n",
      "Extraction started for: 294\n",
      "Extraction started for: 295\n",
      "Extraction started for: 296\n",
      "Extraction started for: 297\n",
      "Extraction started for: 298\n",
      "Extraction started for: 299\n",
      "Extraction started for: 300\n",
      "Extraction started for: 301\n",
      "Extraction started for: 302\n",
      "Extraction started for: 303\n",
      "Extraction started for: 304\n",
      "Extraction started for: 305\n",
      "Extraction started for: 306\n",
      "Extraction started for: 307\n",
      "Extraction started for: 308\n",
      "Extraction started for: 310\n",
      "Extraction started for: 311\n",
      "Extraction started for: 312\n",
      "Extraction started for: 313\n",
      "Extraction started for: 314\n",
      "Extraction started for: 316\n",
      "Extraction started for: 317\n",
      "Extraction started for: 319\n",
      "Extraction started for: 320\n",
      "Extraction started for: 321\n",
      "Extraction started for: 322\n",
      "Extraction started for: 323\n",
      "Extraction started for: 324\n",
      "Extraction started for: 325\n",
      "Extraction started for: 326\n",
      "Extraction started for: 328\n",
      "Extraction started for: 329\n",
      "Extraction started for: 330\n",
      "Extraction started for: 331\n",
      "Extraction started for: 442\n",
      "Extraction started for: 443\n",
      "Extraction started for: 445\n",
      "Extraction started for: 446\n",
      "Extraction started for: 447\n",
      "Extraction started for: 448\n",
      "Extraction started for: 449\n",
      "Extraction started for: 450\n",
      "Extraction started for: 451\n",
      "Extraction started for: 452\n",
      "Extraction started for: 453\n",
      "Extraction started for: 456\n",
      "Extraction started for: 457\n",
      "Extraction started for: 458\n",
      "Extraction started for: 459\n",
      "Extraction started for: 460\n",
      "Extraction started for: 461\n",
      "Extraction started for: 462\n",
      "Extraction started for: 463\n",
      "Extraction started for: 464\n",
      "Extraction started for: 465\n",
      "Extraction started for: 466\n",
      "Extraction started for: 467\n",
      "Extraction started for: 473\n",
      "Extraction started for: 474\n",
      "Extraction started for: 475\n",
      "Extraction started for: 476\n",
      "Extraction started for: 477\n",
      "Extraction started for: 478\n",
      "Extraction started for: 479\n",
      "Extraction started for: 480\n",
      "Extraction started for: 481\n",
      "Extraction started for: 482\n",
      "Extraction started for: 483\n",
      "Extraction started for: 484\n",
      "Extraction started for: 485\n",
      "Extraction started for: 486\n",
      "Extraction started for: 488\n",
      "Extraction started for: 489\n",
      "Extraction started for: 490\n",
      "Extraction started for: 491\n",
      "Extraction started for: 492\n",
      "Extraction started for: 493\n",
      "Extraction started for: 495\n",
      "Extraction started for: 496\n",
      "Extraction started for: 499\n",
      "Extraction started for: 500\n",
      "Extraction started for: 501\n",
      "Extraction started for: 502\n",
      "Extraction started for: 503\n",
      "Extraction started for: 504\n",
      "Extraction started for: 505\n",
      "Extraction started for: 506\n",
      "Extraction started for: 507\n",
      "Extraction started for: 508\n",
      "Extraction started for: 509\n",
      "Extraction started for: 510\n",
      "Extraction started for: 511\n",
      "Extraction started for: 512\n",
      "Extraction started for: 513\n",
      "Extraction started for: 514\n",
      "Extraction started for: 515\n",
      "Extraction started for: 516\n",
      "Extraction started for: 517\n",
      "Extraction started for: 518\n"
     ]
    }
   ],
   "source": [
    "# More stats\n",
    "\n",
    "infoPath = 'C:\\\\Users\\\\Huriye\\\\Documents\\\\code\\\\clapfcstimulation\\\\analysis\\\\infoForAnalysis-extracted.pkl'\n",
    "\n",
    "info = pd.read_pickle(infoPath)\n",
    "info.recordingList.loc[318,'extractedVar'] = 0 # weird paq file - excluded.\n",
    "\n",
    "# Create the main variables for plots by merging the extracted variables from all recordings\n",
    "analysisWindowDur = 2000 # in ms\n",
    "analysisWindowDur = int(np.ceil(analysisWindowDur/fRate))\n",
    "analysis_frame = analysisWindowDur\n",
    "pre_analysisWindow = np.arange(pre_frames - analysis_frame, pre_frames)\n",
    "post_analysisWindow = np.arange((pre_frames+simulationDur), (pre_frames + simulationDur + analysis_frame))\n",
    "\n",
    "# Create dictionaries to store the values\n",
    "variance_dict_pre = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "variance_dict_post = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "snr_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "#mi_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "\n",
    "for ind, recordingDate in enumerate(info.recordingList.recordingDate):\n",
    "    if info.recordingList.extractedVar[ind] == 1:\n",
    "        # Load the extracted values\n",
    "        pathname = info.recordingList.analysispathname[ind]\n",
    "        extData = pd.read_pickle(pathname + 'extracted_variables.pkl')\n",
    "        print('Extraction started for:', ind)\n",
    "        len_cellID = len(extData[15])\n",
    "\n",
    "        # Loop through the datasets ('Both', 'onlyVis', 'onlyOpto')\n",
    "        for dataset in ['Both', 'onlyVis', 'onlyOpto']:\n",
    "            dff_trace = extData[3]\n",
    "            if dataset in dff_trace:\n",
    "                flu = dff_trace[dataset]\n",
    "                # Calculate variance\n",
    "                variance_value_pre = mfun.variance_cell_rates(flu, pre_analysisWindow)\n",
    "                variance_dict_pre[dataset] += variance_value_pre.tolist()\n",
    "                variance_value_post = mfun.variance_cell_rates(flu, post_analysisWindow)\n",
    "                variance_dict_post[dataset] += variance_value_post.tolist()\n",
    "\n",
    "                # Calculate SNR\n",
    "                snr_value = mfun.calculate_SNR(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                snr_dict[dataset] += snr_value.tolist()\n",
    "\n",
    "                # Calculate MI (if applicable)\n",
    "                #mi_value = mfun.calculate_MI(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                #mi_dict[dataset] += mi_value.tolist()\n",
    "            else:\n",
    "                if 'onlyOpto' in dff_trace:\n",
    "                    fakeOpto = np.empty(np.shape(dff_trace['Both']))\n",
    "                else:\n",
    "                    fakeOpto = np.empty(1)\n",
    "                fakeOpto[:] = np.nan\n",
    "\n",
    "                variance_dict_pre[dataset] += fakeOpto.tolist()\n",
    "                variance_dict_post[dataset] += fakeOpto.tolist()\n",
    "                snr_dict[dataset] += fakeOpto.tolist()\n",
    "               # mi_dict[dataset] += fakeOpto.tolist()\n",
    "\n",
    "# Extract the calculated values\n",
    "varianceBoth_pre = variance_dict_pre['Both']\n",
    "varianceVis_pre = variance_dict_pre['onlyVis']\n",
    "varianceOpto_pre = variance_dict_pre['onlyOpto']\n",
    "\n",
    "varianceBoth_post = variance_dict_post['Both']\n",
    "varianceVis_post = variance_dict_post['onlyVis']\n",
    "varianceOpto_post = variance_dict_post['onlyOpto']\n",
    "\n",
    "snrBoth = snr_dict['Both']\n",
    "snrVis = snr_dict['onlyVis']\n",
    "snrOpto = snr_dict['onlyOpto']\n",
    "\n",
    "#miBoth = mi_dict['Both']\n",
    "#miVis = mi_dict['onlyVis']\n",
    "#miOpto = mi_dict['onlyOpto']\n",
    "\n",
    "filenameINFO = info.analysisPath + '\\\\infoForAnalysis-readyForPlotting_moreStats.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((varianceBoth_pre, varianceVis_pre, varianceOpto_pre,\n",
    "                varianceBoth_post, varianceVis_post, varianceOpto_post,\n",
    "                snrBoth,snrVis,snrOpto), f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clapfcstimulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff0e9250df7e90987fa5ad44ef5c9f564e89158a37eae3ca2a18a9b188d147c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
