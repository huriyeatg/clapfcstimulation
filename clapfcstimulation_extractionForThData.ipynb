{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, pickle, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import main_funcs as mfun\n",
    "import utils_funcs as utils\n",
    "import plot_funcs as pfun\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import glob\n",
    "from scipy.signal import resample\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "warnings.filterwarnings(\"ignore\", category= FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category= DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category= UserWarning)\n",
    "\n",
    "pfun.set_figure()\n",
    "\n",
    "\n",
    "## Parameters\n",
    "fRate = 1000/30\n",
    "pre_frames, post_frames, analysisWindowDur, simulationDur = pfun.set_analysisParams ()\n",
    "responsiveness_test_duration = 1000.0 #in ms\n",
    "simulationDur_ms = 350.0 # in ms \n",
    "simulationDur  = int(np.ceil(simulationDur_ms/fRate))\n",
    "shutterLength  = int(np.round(simulationDur_ms/fRate))\n",
    "tTypes = ['All','Both', 'onlyOpto', 'onlyVis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all recordings - MUST BE RUN TO UPDATE THE INFO FILE\n",
    "# For each recording one file saved, each index is a cell \n",
    "# Define the parent directory\n",
    "base_dir = r\"C:\\Users\\Huriye\\Documents\\code\\clapfcstimulation\\analysis\"  \n",
    "\n",
    "# Loop through folders starting with \"2025\"\n",
    "for ind, folder_name in enumerate(os.listdir(base_dir)):\n",
    "   folder_path = os.path.join(base_dir, folder_name)\n",
    "   if os.path.isdir(folder_path) and folder_name.startswith(\"2025\"):\n",
    "      pkl_path = os.path.join(folder_path, \"extracted_variables.pkl\")\n",
    "      savepathname = folder_path + '\\\\'\n",
    "      filenamePAQ_analysis = [f for f in glob.glob(savepathname + 'extracted_variables.pkl')] # paq analysis file\n",
    "      if ind>0: #try:\n",
    "         print(str(ind) + ': Creating: ' +savepathname)\n",
    "         #Create a huge dictionary with all cells and parameters for each cell\n",
    "         pathname = savepathname\n",
    "         print('Creating the dict for:' + pathname)\n",
    "\n",
    "         ########## Organise stimuli times \n",
    "         if  True: #(info.recordingList.paqExtraction[ind] ==1) :\n",
    "            paqData = pd.read_pickle (pathname +'paq-data.pkl')\n",
    "            paqRate = paqData['rate']\n",
    "            # Get the stim start times \n",
    "            frame_clock    = utils.paq_data (paqData, 'prairieFrame', threshold_ttl=True, plot=False)\n",
    "            optoStimTimes  = utils.paq_data (paqData, 'optoLoopback', threshold_ttl=True, plot=False)\n",
    "            if   (len(optoStimTimes)>500):\n",
    "\n",
    "               print('Opto stim times is a lot , check it out : ' + str(ind))\n",
    "            else: # the frame_clock is slightly longer in paq as there are some up to a sec delay from\n",
    "               # microscope to PAQI/O software.  \n",
    "               optoStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='optoLoopback',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               visStimTimes = utils.stim_start_frame (paq=paqData, stim_chan_name='maskerLED',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               shutterTimes = utils.shutter_start_frame (paq=paqData, stim_chan_name='shutterLoopback',\n",
    "                                                   frame_clock=None,stim_times=None, plane=0, n_planes=1)\n",
    "               # Lets organise it more for analysis friendly format\n",
    "               trialStartTimes = np.unique(np.concatenate((optoStimTimes,visStimTimes),0))\n",
    "               # final check if there is a problematic stim start\n",
    "               first_ind = np.where(np.diff(trialStartTimes)>30) # should be at least one sec between stim starts\n",
    "               first_ind = np.concatenate(([0], first_ind[0]+1))\n",
    "               trialStartTimes = np.array(trialStartTimes)\n",
    "               trialStartTimes = trialStartTimes[first_ind]\n",
    "               trialTypes = []\n",
    "\n",
    "               for t in trialStartTimes:\n",
    "                  optoexist =  np.any(optoStimTimes== t)\n",
    "                  visexist  =  np.any( visStimTimes == t)\n",
    "                  if  optoexist  & visexist: \n",
    "                     trialTypes += ['Both']\n",
    "                  elif optoexist &~ visexist:\n",
    "                     trialTypes += ['onlyOpto']\n",
    "                  elif ~optoexist & visexist:\n",
    "                     trialTypes += ['onlyVis']\n",
    "                  else:\n",
    "                     trialTypes += ['CHECK']\n",
    "               trialStartTimes = shutterTimes\n",
    "               #t = [idx for idx, t_type in enumerate(trialTypes) if t_type=='Both']\n",
    "            \n",
    "            ########## Organise calcium imaging traces \n",
    "            pvals ={} \n",
    "            pvalsWilcoxon = {}\n",
    "            dffTrace ={} \n",
    "            dffTrace_mean ={}\n",
    "            dffTrace_median ={}\n",
    "            dffAfterStim1500ms_mean ={}\n",
    "            dffTrace_normalised = {}\n",
    "            dffTrace_mean_normalised ={}\n",
    "            \n",
    "            if True:\n",
    "               imData = pd.read_pickle (pathname +'imaging-data.pkl')\n",
    "               fluR      = imData['flu']\n",
    "               n_frames  = imData['n_frames']\n",
    "               flu_raw   = imData['flu_raw']\n",
    "\n",
    "               # Lets put nans for stimulated frames\n",
    "               frameTimes = np.full((1,fluR.shape[1] ), False) # create a full false array\n",
    "               for sT in shutterTimes:\n",
    "                  frameTimes[:,sT:(sT+shutterLength)] = True\n",
    "               fluR[:, frameTimes[0,:]] = np.nan\n",
    "\n",
    "               # clean detrended traces\n",
    "               flu = utils.clean_traces(fluR)\n",
    "               flu_normalised = mfun.norm_to_zero_one (flu)\n",
    "\n",
    "               ### Look for responsiveness for 4 trial types\n",
    "               for t in tTypes:\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  elif t =='onlyVis':\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyVis']\n",
    "                  elif t =='onlyOpto':\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyOpto']\n",
    "                  elif t =='Both':  \n",
    "                     # Get indices of each type\n",
    "                     visual_inds = [idx for idx, t_type in enumerate(trialTypes) if t_type == 'onlyVis']\n",
    "                     opto_inds = [idx for idx, t_type in enumerate(trialTypes) if t_type == 'Both']         \n",
    "                     # Determine number to sample from each\n",
    "                     half_n = min(len(visual_inds), len(opto_inds)) // 2\n",
    "                     # Randomly sample from each group\n",
    "                     selected_visual = np.random.choice(visual_inds, size=half_n, replace=False)\n",
    "                     selected_opto = np.random.choice(opto_inds, size=half_n, replace=False)\n",
    "                     # Combine and sort\n",
    "                     trialInd = np.sort(np.concatenate([visual_inds, selected_opto]))\n",
    "                     #trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyVis']\n",
    "                     tBoth = trialInd\n",
    "                                    \n",
    "                  if len(trialInd)>1:\n",
    "                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "                                                               post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "                                                               testType ='ttest')\n",
    "                     pvals[t] = pval\n",
    "                     _, _, pval = utils.test_responsive  (flu, frame_clock, trialStartTimes[trialInd], pre_frames=int(np.ceil(responsiveness_test_duration/fRate)), \n",
    "                                                               post_frames=int(np.ceil(responsiveness_test_duration/fRate)), offset=simulationDur,\n",
    "                                                               testType ='wilcoxon')\n",
    "                     pvalsWilcoxon[t] = pval\n",
    "               nCell = len(flu)\n",
    "               print('number of cell: ' + str(nCell))\n",
    "               ### Get dff values for 4 trial types\n",
    "               for indx, t in enumerate(tTypes) :\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  elif t =='onlyVis':\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyVis']\n",
    "                  elif t =='onlyOpto':\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyOpto']\n",
    "                  elif t =='Both':  \n",
    "                     # # Get indices of each type\n",
    "                     # visual_inds = [idx for idx, t_type in enumerate(trialTypes) if t_type == 'onlyVis']\n",
    "                     # opto_inds = [idx for idx, t_type in enumerate(trialTypes) if t_type == 'onlyVis']         \n",
    "                     # # Determine number to sample from each\n",
    "                     # half_n = min(len(visual_inds), len(opto_inds)) // 2\n",
    "                     # # Randomly sample from each group\n",
    "                     # selected_visual = np.random.choice(visual_inds, size=half_n, replace=False)\n",
    "                     # selected_opto = np.random.choice(opto_inds, size=half_n, replace=False)\n",
    "                     # # Combine and sort\n",
    "                     # trialInd = np.sort(np.concatenate([selected_visual, selected_opto]))\n",
    "                     trialInd = tBoth\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     dffTrace[t]      = utils.flu_splitter(flu, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     dffTrace_mean[t] = np.mean(dffTrace[t],2) # Cell x time\n",
    "                     dffTrace_median[t] = np.median(dffTrace[t],2) # Cell x time\n",
    "                     dffAfterStim1500ms_mean[t] = np.nanmean(dffTrace_mean[t][:, (pre_frames+simulationDur): (pre_frames + analysisWindowDur)],1)\n",
    "                     \n",
    "                     dffTrace_normalised[t] = utils.flu_splitter(flu_normalised, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     dffTrace_mean_normalised[t] = np.mean (dffTrace_normalised[t],2) # Cell x time ( mean - 2)\n",
    "\n",
    "            ########## Organise pupil  traces \n",
    "            pupilTrace ={}\n",
    "            pupilTrace_mean ={}\n",
    "            pupilTraceVer ={}\n",
    "            pupilTrace_meanVer ={}\n",
    "\n",
    "            if True:\n",
    "               pupilData = pd.read_pickle (pathname +'pupil-data.pkl')\n",
    "               pupilrawh = pupilData['horizontalDis']\n",
    "               pupilrawv = pupilData['verticalDis']\n",
    "               pupilQualityh = pupilData['horizontallikelihood']\n",
    "               pupilQualityv = pupilData['verticallikelihood']\n",
    "\n",
    "               for indx, t in enumerate(tTypes) :\n",
    "                  if t =='All':\n",
    "                     trialInd = np.transpose(list(range(len(trialStartTimes))))\n",
    "                  elif t =='onlyVis':\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyVis']\n",
    "                  elif t =='onlyOpto':\n",
    "                     trialInd = [idx for idx, t_type in enumerate(trialTypes) if t_type=='onlyOpto']\n",
    "                  elif t =='Both':  \n",
    "                     # # Get indices of each type\n",
    "                     # visual_inds = [idx for idx, t_type in enumerate(trialTypes) if t_type == 'onlyVis']\n",
    "                     # opto_inds = [idx for idx, t_type in enumerate(trialTypes) if t_type == 'onlyVis']         \n",
    "                     # # Determine number to sample from each\n",
    "                     # half_n = min(len(visual_inds), len(opto_inds)) // 2\n",
    "                     # # Randomly sample from each group\n",
    "                     # selected_visual = np.random.choice(visual_inds, size=half_n, replace=False)\n",
    "                     # selected_opto = np.random.choice(opto_inds, size=half_n, replace=False)\n",
    "                     # # Combine and sort\n",
    "                     # trialInd = np.sort(np.concatenate([selected_visual, selected_opto]))\n",
    "                     trialInd = tBoth\n",
    "                  \n",
    "                  if len(trialInd)>1:\n",
    "                     pupilTrace[t]  = utils.trace_splitter(pupilrawh, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     pupilTrace_mean[t]  = np.mean(pupilTrace[t],2) # Cell x time\n",
    "\n",
    "                     pupilTraceVer[t]  = utils.trace_splitter(pupilrawv, trialStartTimes[trialInd], pre_frames, post_frames) # Cell x time x trial\n",
    "                     pupilTrace_meanVer[t]  = np.mean(pupilTraceVer[t],2) # Cell x tim\n",
    "\n",
    "            #lets get recording info\n",
    "            animalID = []\n",
    "            x_coordinate = []\n",
    "            y_coordinate = []\n",
    "            z_coordinate = []\n",
    "            stimuliFamilarity = []\n",
    "            dataQuality =[]\n",
    "            recData = []\n",
    "            recID   = []\n",
    "            cellID  = []\n",
    "\n",
    "            if len(imData)>0:\n",
    "               imStats = imData['stat']\n",
    "               for idx, cell_flu in enumerate(flu): # from suite2p website: med: (y,x) center of cell\n",
    "                  x_coordinate += [0]#[np.round(imStats[idx]['med'][1] *512/558.9) + info.recordingList['x-coordinate'] [ind]]\n",
    "                  y_coordinate += [0]#[np.round(imStats[idx]['med'][0] *512/558.9) + info.recordingList['y-coordinate'] [ind]]\n",
    "                  z_coordinate += [0]#[info.recordingList['z-coordinate'] [ind]]\n",
    "                  animalID     += [25000] # [info.recordingList['animalID'] [ind]]\n",
    "                  stimuliFamilarity += [21]# [info.recordingList['stimuliFamiliarity'] [ind]]\n",
    "                  dataQuality  += [1]#[info.recordingList['dataQuality'] [ind]]\n",
    "                  recData  += [0]#[info.recordingList['recordingDate'] [ind]]\n",
    "                  recID    += [0]#[info.recordingList['recordingID'] [ind]]\n",
    "                  cellID   += [idx]\n",
    "\n",
    "            #save outputs for population analysis\n",
    "            savename = pathname + '\\\\extracted_variablesTH.pkl'\n",
    "            with open(savename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "               pickle.dump([trialStartTimes, trialTypes, pvals, dffTrace, \n",
    "                           dffTrace_mean, dffAfterStim1500ms_mean,\n",
    "                           x_coordinate,y_coordinate,z_coordinate,\n",
    "                           animalID,stimuliFamilarity,pvalsWilcoxon, dataQuality,\n",
    "                           recData, recID, cellID, pupilTrace, pupilTrace_mean, \n",
    "                           pupilQualityh, pupilTraceVer, pupilTrace_meanVer, pupilQualityv,\n",
    "                           dffTrace_normalised,dffTrace_mean_normalised, dffTrace_median], f)\n",
    "\n",
    "      #except:\n",
    "      #   print('FAILED: ' + pathname)\n",
    "   \n",
    "print('All should be done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge all datapoints & save them in a dictionary\n",
    "\n",
    "\n",
    "# Initialize empty or None types for variables to be aggregated.\n",
    "dff_traceBoth, dff_traceVis, dff_traceOpto = None, None, None\n",
    "dff_traceBoth_median, dff_traceVis_median, dff_traceOpto_median = None, None, None\n",
    "dff_traceBoth_normalised, dff_traceVis_normalised, dff_traceOpto_normalised = None, None, None\n",
    "pupil_traceBoth, pupil_traceVis, pupil_traceOpto = None, None, None\n",
    "pupilID, x_coordinate, y_coordinate, z_coordinate = [], [], [], []\n",
    "animalID, stimuliFamilarity, dataQuality, recData, recID, cellID = [], [], [], [], [], []\n",
    "pvalsBoth, pvalsVis, pvalsOpto = [], [], []\n",
    "dff_meanBothValue, dff_meanVisValue, dff_meanOptoValue = [], [], []\n",
    "\n",
    "# Create the main variables for plots by merging the extracted variables from all recordings\n",
    "ty = 0\n",
    "indPupil = 0\n",
    "\n",
    "base_dir = r\"C:\\Users\\Huriye\\Documents\\code\\clapfcstimulation\\analysis\"  \n",
    "\n",
    "# Loop through folders starting with \"2025\"\n",
    "for ind, folder_name in enumerate(os.listdir(base_dir)):\n",
    "   folder_path = os.path.join(base_dir, folder_name)\n",
    "   if os.path.isdir(folder_path) and folder_name.startswith(\"2025\"):\n",
    "        pathname = folder_path + '\\\\'\n",
    "        extData = pd.read_pickle (pathname + 'extracted_variablesTH.pkl')\n",
    "        sys.stdout.write(f'\\rExtraction started for : {ind}')\n",
    "        sys.stdout.flush() \n",
    "\n",
    "        len_cellID   = len(extData[15])\n",
    "        if len_cellID==0:\n",
    "            len_cellID=1\n",
    "\n",
    "        # Get Dff traces MEAN\n",
    "        dff_trace = extData[4] #4 for mean, 24 for median\n",
    "        shape = (len_cellID, 240) \n",
    "        dff_traceBoth =mfun.update_dff_traces(dff_traceBoth, dff_trace, 'Both', shape)\n",
    "        dff_traceVis = mfun.update_dff_traces(dff_traceVis, dff_trace, 'onlyVis', shape)\n",
    "        dff_traceOpto = mfun.update_dff_traces(dff_traceOpto, dff_trace, 'onlyOpto', shape)\n",
    "\n",
    "        # Get Dff traces MEDIAN\n",
    "        dff_trace = extData[24] #4 for mean, 24 for median\n",
    "        shape = (len_cellID, 240) \n",
    "        dff_traceBoth_median =mfun.update_dff_traces(dff_traceBoth_median, dff_trace, 'Both', shape)\n",
    "        dff_traceVis_median = mfun.update_dff_traces(dff_traceVis_median, dff_trace, 'onlyVis', shape)\n",
    "        dff_traceOpto_median = mfun.update_dff_traces(dff_traceOpto_median, dff_trace, 'onlyOpto', shape)\n",
    "\n",
    "        # Get Dff traces NORMALISED\n",
    "        dff_trace = extData[23] #4 for mean, 24 for median\n",
    "        shape = (len_cellID, 240)\n",
    "        dff_traceBoth_normalised =mfun.update_dff_traces(dff_traceBoth_normalised, dff_trace, 'Both', shape)\n",
    "        dff_traceVis_normalised = mfun.update_dff_traces(dff_traceVis_normalised, dff_trace, 'onlyVis', shape)\n",
    "        dff_traceOpto_normalised = mfun.update_dff_traces(dff_traceOpto_normalised, dff_trace, 'onlyOpto', shape)\n",
    "\n",
    "        # Get Pupil traces\n",
    "        indPupil, pupilID, pupil_traceBoth, pupil_traceVis, pupil_traceOpto = mfun.update_pupil_traces(\n",
    "            extData, len_cellID, indPupil, pupilID, pupil_traceBoth, pupil_traceVis, pupil_traceOpto)\n",
    "        \n",
    "        # Get P values\n",
    "\n",
    "        pvals = extData[2]\n",
    "        if len(pvals)>0:\n",
    "            pvalsBoth += pvals['Both'].tolist()\n",
    "            pvalsVis  += pvals['onlyVis'].tolist()\n",
    "            pvalsOpto  += pvals['onlyOpto'].tolist()\n",
    "        else:\n",
    "            display('Weird')\n",
    "            pvalsBoth += [5]\n",
    "            pvalsVis  += [5]\n",
    "            pvalsOpto += [5]\n",
    "\n",
    "         \n",
    "        # Get  cell-related information\n",
    "        x_coordinate += extData[6]\n",
    "        y_coordinate += extData[7]\n",
    "        z_coordinate += extData[8]\n",
    "        animalID     += extData[9]\n",
    "        stimuliFamilarity += extData[10]\n",
    "        dataQuality += extData[12]\n",
    "        recData  += extData[13]\n",
    "        recID    += extData[14]\n",
    "        cellID   += extData[15]\n",
    "\n",
    "########################################\n",
    "####################### Organise & save files\n",
    "\n",
    "fRate = 1000/30.0\n",
    "pre_frames    = 2000.0# in ms\n",
    "pre_frames    = int(np.ceil(pre_frames/fRate))\n",
    "post_frames   = 6000.0 # in ms\n",
    "post_frames   = int(np.ceil(post_frames/fRate))\n",
    "analysis_time = 1500.0 # in ms\n",
    "analysis_time = int(np.ceil(analysis_time/fRate))\n",
    "simulationDur_ms = 350.0 # in ms\n",
    "simulationDur = int(np.ceil(simulationDur_ms/fRate))\n",
    "pupil_resample_num = int(6*5)\n",
    "\n",
    "### Lets normalise to baseline - MEAN\n",
    "traces = {  'Vis': dff_traceVis,\n",
    "            'Opto': dff_traceOpto,\n",
    "            'Both': dff_traceBoth}\n",
    "\n",
    "dff_traceVis_normalisedtopre, dff_traceOpto_normalisedtopre, dff_traceBoth_normalisedtopre = (\n",
    "    mfun.normalize_to_baseline(traces[key], pre_frames) for key in traces)\n",
    "### Lets do tiny cleaning for imaging traces -MEDIAN\n",
    "traces = {  'Vis': dff_traceVis_median,\n",
    "            'Opto': dff_traceOpto_median,\n",
    "            'Both': dff_traceBoth_median}\n",
    "dff_traceVis_normalisedtopre_median, dff_traceOpto_normalisedtopre_median, dff_traceBoth_normalisedtopre_median = (\n",
    "    mfun.normalize_to_baseline(traces[key], pre_frames) for key in traces)\n",
    "\n",
    "### Lets do tiny cleaning for pupil traces\n",
    "traces = {  'Vis': pupil_traceVis,\n",
    "            'Opto': pupil_traceOpto,\n",
    "            'Both': pupil_traceBoth}\n",
    "pupil_traceVis, pupil_traceOpto, pupil_traceBoth = (\n",
    "    mfun.normalize_to_baseline(traces[key], pre_frames) for key in traces)\n",
    "\n",
    "pupil_traceOpto = resample(pupil_traceOpto, pupil_resample_num, axis=1)\n",
    "pupil_traceVis = resample(pupil_traceVis, pupil_resample_num, axis=1)\n",
    "pupil_traceBoth = resample(pupil_traceBoth, pupil_resample_num, axis=1)\n",
    "\n",
    "#  More version of dff traces\n",
    "dff_meanBoth = np.nanmean(dff_traceBoth [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1)\n",
    "dff_meanVis  = np.nanmean(dff_traceVis  [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1)\n",
    "dff_meanOpto = np.nanmean(dff_traceOpto [:, pre_frames:(pre_frames + simulationDur + analysis_time)],axis=1) \n",
    "\n",
    "zdff_traceBoth = stats.zscore (dff_traceBoth, nan_policy='omit')\n",
    "zdff_traceVis  = stats.zscore (dff_traceVis, nan_policy='omit')\n",
    "zdff_traceOpto = stats.zscore (dff_traceOpto, nan_policy='omit')\n",
    "\n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForSelectingInterestedCells.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((animalID, stimuliFamilarity, dataQuality,\n",
    "                 recData, recID, cellID, \n",
    "                 pvalsBoth, pvalsVis, pvalsOpto,\n",
    "                 dff_meanVis, dff_meanBoth, \n",
    "                 dff_meanOpto, pupilID),f)\n",
    "\n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth, dff_traceVis, dff_traceOpto), f)\n",
    "    \n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting_median.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_median, dff_traceVis_median, dff_traceOpto_median), f)\n",
    "    \n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting_normalised.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalised, dff_traceVis_normalised, dff_traceOpto_normalised), f)\n",
    "    \n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting_normalisedtoPre.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalisedtopre, dff_traceVis_normalisedtopre, dff_traceOpto_normalisedtopre), f)\n",
    "    \n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting_normalisedtoPre_median.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((dff_traceBoth_normalisedtopre_median, dff_traceVis_normalisedtopre_median, dff_traceOpto_normalisedtopre_median), f)\n",
    "    \n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting_position.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((x_coordinate, y_coordinate, z_coordinate ), f)\n",
    "\n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlottingPupil.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((pupil_traceVis, pupil_traceBoth, pupil_traceOpto ), f)\n",
    "print('\\nAll should be done!!')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More stats\n",
    "\n",
    "# Create the main variables for plots by merging the extracted variables from all recordings\n",
    "pre_frames, post_frames, analysis_frame, simulationDur = pfun.set_analysisParams ()\n",
    "pre_analysisWindow = np.arange(pre_frames - analysis_frame, pre_frames)\n",
    "post_analysisWindow = np.arange((pre_frames+simulationDur), (pre_frames + simulationDur + analysis_frame))\n",
    "\n",
    "# Create dictionaries to store the values\n",
    "variance_dict_pre = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "variance_dict_post = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "mi_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "snr_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "abs_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "crosscorr_dict_pre = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "crosscorr_dict_post = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "dtw_dict = {'Both': [], 'onlyVis': [], 'onlyOpto': []}\n",
    "\n",
    "for ind, folder_name in enumerate(os.listdir(base_dir)):\n",
    "   folder_path = os.path.join(base_dir, folder_name)\n",
    "   if os.path.isdir(folder_path) and folder_name.startswith(\"2025\"):\n",
    "        pathname = folder_path + '\\\\'\n",
    "        extData = pd.read_pickle (pathname + 'extracted_variablesTH.pkl')\n",
    "        sys.stdout.write(f'\\rMore stats are calculating for : {ind}')\n",
    "        sys.stdout.flush() \n",
    "        len_cellID = len(extData[15])\n",
    "\n",
    "        # Loop through the datasets ('Both', 'onlyVis', 'onlyOpto')\n",
    "        for dataset in ['Both', 'onlyVis', 'onlyOpto']:\n",
    "            dff_trace = extData[3]\n",
    "            if dataset in dff_trace:\n",
    "                flu = dff_trace[dataset]\n",
    "                # Calculate variance\n",
    "                variance_value_pre = mfun.variance_cell_rates(flu, pre_analysisWindow)\n",
    "                variance_dict_pre[dataset] += variance_value_pre.tolist()\n",
    "                variance_value_post = mfun.variance_cell_rates(flu, post_analysisWindow)\n",
    "                variance_dict_post[dataset] += variance_value_post.tolist()\n",
    "\n",
    "                # Calculate cross-correlation\n",
    "                crosscorr_value_post = mfun.mean_cross_correlation(flu, pre_analysisWindow)\n",
    "                crosscorr_dict_pre[dataset] += crosscorr_value_post.tolist()\n",
    "\n",
    "                crosscorr_value_post = mfun.mean_cross_correlation(flu, post_analysisWindow)\n",
    "                crosscorr_dict_post[dataset] += crosscorr_value_post.tolist()\n",
    "\n",
    "                # Calculate SNR\n",
    "                snr_value = mfun.calculate_SNR(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                snr_dict[dataset] += snr_value.tolist()\n",
    "\n",
    "                # Calculate Absolute Value\n",
    "                abs_value = mfun.calculate_absMagnitude(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                abs_dict[dataset] += abs_value.tolist()\n",
    "\n",
    "                # Calculate MI (if applicable)\n",
    "                mi_value = mfun.calculate_MI(flu, pre_analysisWindow, post_analysisWindow)\n",
    "                mi_dict[dataset] += mi_value.tolist()\n",
    "\n",
    "                # Calculate DTW\n",
    "                dtw_value = mfun.calculate_per_cell_dtw(flu, post_analysisWindow)\n",
    "                dtw_dict[dataset] += dtw_value.tolist()  \n",
    "            else:\n",
    "                if 'onlyOpto' in dff_trace:\n",
    "                    fakeOpto = np.empty(np.shape(dff_trace['Both']))\n",
    "                else:\n",
    "                    fakeOpto = np.empty(1)\n",
    "                fakeOpto[:] = np.nan\n",
    "\n",
    "                variance_dict_pre[dataset] += fakeOpto.tolist()\n",
    "                variance_dict_post[dataset] += fakeOpto.tolist()\n",
    "                crosscorr_dict_pre[dataset] += fakeOpto.tolist()\n",
    "                crosscorr_dict_post[dataset] += fakeOpto.tolist()\n",
    "                snr_dict[dataset] += fakeOpto.tolist()\n",
    "                abs_dict[dataset] += fakeOpto.tolist()\n",
    "                mi_dict[dataset] += fakeOpto.tolist()\n",
    "                dtw_dict[dataset] += fakeOpto.tolist() \n",
    "\n",
    "filenameINFO = base_dir + '\\\\infoForAnalysisTH-readyForPlotting_moreStats.pkl'\n",
    "with open(filenameINFO, 'wb') as f:\n",
    "    pickle.dump((variance_dict_pre, variance_dict_post, snr_dict, mi_dict,\n",
    "                 crosscorr_dict_pre,crosscorr_dict_post, abs_dict,dtw_dict), f)\n",
    "    \n",
    "print('\\nCompleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary figure : Chrimson in Th mice - Naive population analysis Increase variance in response\n",
    "\n",
    "interestedCohort = 'Th'\n",
    "interestedTrainedLevel = 'Naive'\n",
    "\n",
    "pfun.set_figure()\n",
    "fig = plt.figure(constrained_layout=False, figsize=(16, 18)) # 8,11 for full A4 page\n",
    "# figsize=(6.85, 9.05)) for full page # figsize=(3.35, 9.05)) for single page\n",
    "\n",
    "# set gridspec\n",
    "gs_visHeatmap  = fig.add_gridspec(ncols=3, nrows=1, bottom=0.65, top=0.95, left=0.05,right=0.46,\n",
    "                              wspace=0.1, hspace=0.2)\n",
    "gs_visHeatmapCax  = fig.add_gridspec(ncols=1, nrows=1, bottom=0.65, top=0.95, left=0.48, right=0.50,\n",
    "                              wspace=0.2, hspace=0.4)\n",
    "gs_visuaPlots  = fig.add_gridspec(ncols=3, nrows=2, bottom=0.65, top=0.95, left=0.56, right=0.95,\n",
    "                              wspace=0.3, hspace=0.4)\n",
    "gs_optoPlots   = fig.add_gridspec(ncols=5, nrows=1, bottom=0.46, top=0.59, left=0.0, right=0.95,\n",
    "                             width_ratios=[0.8, 0.8, 1, 1, 1], wspace=0.45, hspace=0.4)\n",
    "gs_bothPlots   = fig.add_gridspec(ncols=5, nrows=1, bottom=0.27, top=0.40, left=0.0, right=0.95,\n",
    "                             width_ratios=[0.8, 0.8, 1, 1, 1], wspace=0.45, hspace=0.4)\n",
    "\n",
    "# Panel A: Heatmap for Visual responsive cells\n",
    "ax_gs_visHeatmap = {xx: fig.add_subplot(gs_visHeatmap[xx]) for xx in range(3)}\n",
    "cax =  {xx: fig.add_subplot(gs_visHeatmapCax[xx]) for xx in range(1)} \n",
    "colorbarlimitsForHeatMap = [-1,1] \n",
    "pfun.heatmap_comparison('Visual', 'Visual + Opto', sortType = 'Visual', cohort=interestedCohort, \n",
    "                       trainedLevel= interestedTrainedLevel, condition='Sensory',\n",
    "                       colormapSelection = 'OptoProject', axis=ax_gs_visHeatmap, cbar_ax=cax[0], \n",
    "                       savefigname=None, savefigpath=None, colorbarlimits=colorbarlimitsForHeatMap)\n",
    "\n",
    "# Panel B-G: Visual responsive cells analysis\n",
    "plotParams = {\n",
    "    'ylimitsforhist': [0, 50],\n",
    "    'xlimitsforhist': [-0.75, 0.75],\n",
    "    'analysis_time': 1500,  # in ms\n",
    "    'colorbarlimitsForHeatMap': [-2, 2],\n",
    "    'scatterplotlimits': [-4.5, 4.5],\n",
    "    'ylimitsforECDF': [0.5, 1.05],\n",
    "    'xlimitsforABS': [-0.05, 1.2],\n",
    "    'ylimitsforCV': [0.1, 0.15],\n",
    "    'faceColors': ['black','red'],\n",
    "     }\n",
    "\n",
    "total_num_axis = gs_visuaPlots.get_geometry()[0]* gs_visuaPlots.get_geometry()[1]\n",
    "ax_gs_visuaPlots = {xx: fig.add_subplot(gs_visuaPlots[xx]) for xx in range(total_num_axis)}\n",
    "pfun.population_plots('Visual', 'Visual + Opto', sortType = 'Visual', cohort=interestedCohort, \n",
    "                       trainedLevel=interestedTrainedLevel, condition='Sensory', plotParams = plotParams,\n",
    "                       axisAll=ax_gs_visuaPlots, savefigname=None, savefigpath=None)\n",
    "\n",
    "# Panel: Opto responsive cells analysis\n",
    "total_num_axis = gs_optoPlots.get_geometry()[0]* gs_optoPlots.get_geometry()[1]\n",
    "ax_gs_optoPlots = {xx: fig.add_subplot(gs_optoPlots[xx]) for xx in range(total_num_axis)}\n",
    "plotParams['faceColors'] = ['black', 'blue']\n",
    "plotParams['ylimitsforhist'] = [0, 100]\n",
    "pfun.population_plots('Visual', 'Visual + Opto', sortType = 'Visual', cohort=interestedCohort, \n",
    "                      trainedLevel=interestedTrainedLevel, condition='Opto', plotParams = plotParams,\n",
    "                      axisAll=ax_gs_optoPlots, savefigname=None, savefigpath=None)\n",
    "\n",
    "# Panel: OptoBoosted responsive cells analysis\n",
    "total_num_axis = gs_bothPlots.get_geometry()[0]* gs_bothPlots.get_geometry()[1]\n",
    "ax_gs_bothPlots = {xx: fig.add_subplot(gs_bothPlots[xx]) for xx in range(total_num_axis)}\n",
    "plotParams['faceColors'] = ['black', 'green']\n",
    "plotParams['ylimitsforhist'] = [0, 20]\n",
    "pfun.population_plots('Visual', 'Visual + Opto', sortType = 'Visual', cohort=interestedCohort, \n",
    "                       trainedLevel=interestedTrainedLevel, condition='Opto-boosted', plotParams = plotParams,\n",
    "                       axisAll=ax_gs_bothPlots, savefigname=None, savefigpath=None)\n",
    "\n",
    "# Lets add the labels\n",
    "axes = [ax_gs_visHeatmap, ax_gs_visuaPlots, ax_gs_optoPlots, ax_gs_bothPlots]\n",
    "labels = ['A','B','C','D','','E','F','G','','H','','I','J','K','L','','M','N','O','P',\n",
    "          'Q','R','S','T','U','V','W','X','Y','','Z']\n",
    "lInd = 0\n",
    "skip_indices = [68, 70, 75]\n",
    "for ax, label in zip(axes, labels):\n",
    "    for key in ax:\n",
    "        # if 8/10/15, do not add the label\n",
    "        if lInd not in skip_indices:\n",
    "            if lInd<3:\n",
    "                ax[key].text(-0.04, 1.04, labels[lInd], transform=ax[key].transAxes, fontsize=16, \n",
    "                            fontweight='bold', va='top', ha='right',\n",
    "                            bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "            elif lInd>2:\n",
    "                ax[key].text(-0.08, 1.1, labels[lInd], transform=ax[key].transAxes, fontsize=16, \n",
    "                            fontweight='bold', va='top', ha='right',\n",
    "                            bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "            else:\n",
    "                ax[key].text(-0.04, 1.04, labels[lInd], transform=ax[key].transAxes, fontsize=16, \n",
    "                            fontweight='bold', va='top', ha='right',\n",
    "                            bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "        lInd += 1\n",
    "\n",
    "# Add some text in the figure  \n",
    "axes[1][1].text(2.5, 1.3, 'Sensory responsive neurons', transform=axes[1][0].transAxes, fontsize=16, \n",
    "                        fontweight='bold', va='top', ha='right',\n",
    "                        bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "              \n",
    "axes[2][1].text(3.5, 1.2, 'Opto responsive neurons', transform=axes[2][1].transAxes, fontsize=16, \n",
    "                        fontweight='bold', va='top', ha='right',\n",
    "                        bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "\n",
    "axes[3][1].text(3.5, 1.2, 'Opto-boosted neurons', transform=axes[3][1].transAxes, fontsize=16, \n",
    "                        fontweight='bold', va='top', ha='right',\n",
    "                        bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.1'))\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "savefigpath  =  r'G:\\My Drive\\Manuscripts\\0 CLAStPFC\\panels_raw2'\n",
    "savefigname = 'Supp_Th_NaivePopulationAnalysisRawSorted'\n",
    "pfun.save_figure(savefigname,savefigpath)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clapfcstimulation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff0e9250df7e90987fa5ad44ef5c9f564e89158a37eae3ca2a18a9b188d147c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
